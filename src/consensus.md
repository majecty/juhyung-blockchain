# Consensus

프로그래머로서 블록체인의 핵심은 합의라고 생각한다. 여러 합의 방법이 있을 수 있지만,
그 중 가장 잘 동작하고 있는 방식은 PoW라고 생각한다.

PoW는 블록체인 네트워크에 참여한 모든 컴퓨터들이 각자 랜덤한 숫자를 끊임 없이 계산한다.
각 숫자마다 점수가 있어서, 해당 차례에 필요한 최소 점수보다 높은 점수를 계산하는 컴퓨터가
다음 블록을 생성할 권리를 얻는다.

## 경제적인 알고리즘

PoW으로 합의하는 방식은 그 전까지 내가 생각하던 알고리즘과 달랐다. 내가 생각하는 알고리즘은
내가 전지적인 지적 설계자가 되어서 모든 요소들의 트레이드오프를 고려한 뒤 적절한 방식을 결정했다.
PoW는 다르다. PoW가 잘 동작하려면, 한 노드가 생성한 블록이 전체 네트워크에 잘 퍼져야 한다.
과연 한 노드 작성한 블록을 다른 노드들이 전세계 네트워크에 잘 퍼뜨려 줄까?

블록체인 분야에서 재밌고, 또한 어려운 점은, 컴퓨터가 경제적인 주체라는 점이다. 나는 로봇도 만들어 봤고,
게임도 만들어봤고, 앱도 만들어봤지만, 아직까지 컴퓨터가 경제적인 주체라는 점은 고려해본 적이 없었다.
로봇은 내가 명령한 대로만 움직였다. 게임은 간혹 사람들이 해킹을 시도했긴 했지만, 해당 행동은 찾아서 막아야 했다.
블록체인에서는, 의사소통하는 규칙만 맞으면 세부적인 동작 방식은 자유로웠다.
내 노드가 생성한 블록을 다른 노드에 전달할지 말지는 다른 노드의 자유란 의미다. 누구든지 소스코드를
수정해서 다른 동작을 만들어도 괜찮은 동네다.

PoW에서 다른 노드가 생성한 블록을 퍼뜨리는 이유는, 그것이 경제적으로 이득이 되기 때문이다.
내가 생성하게될 미래의 블록의 점수는 해당 블록이 쌓아온 모든 역사를 포함하는 점수다.
따라서 다른 사람이 만든 하나라도 높은 블록 위에 내 블록을 쌓는 것이 이득이다.
또한 그 다른 사람이 만든 블록이 전체 네트워크에 잘 알려져야 한다.

블록체인 업계에서 공부하다 보면, 경제적인 인센티브를 고려하는 많은 서비스들을 볼 수 있다.
서비스들이 이야기하는 알고리즘들을 공부하고, 이해하려고 하다 보면, 경제적인 부분에서 막힐 때가 많다.
정말 모두 의도한 대로 이득을 찾아 행동할까? 코너케이스로 나쁜 찟 하는게 이득이면 어떡하지.
경제적 인센티브의 예외사항들은 어떻게 찾아야하나.

## 분산화

블록체인을 처음 공부할 때 분산화의 개념이 쉬이 이해되지 않았다.
중앙에서 관리하는 개인 혹은 단체가 없다는 말 자체는 의미를 알 수 있었다.
그렇다면 분산화 된 프로그램에서 문제가 생겼을 때 어떤 일이 일어나는지 궁금했다.
게임은 문제가 생기면 디비 데이터를 되돌릴 수 있다. 누군가 주도권을 가지고 있지 않다면
문제가 생겼을 때 어떻게 해야하는가.

가장 간단하게 생각해보면 처음부터 문제가 없는 규칙을 만들면 된다. 우리 모두 알고 있듯이,
처음부터 완벽한 걸 만들 수 없다. 분산화된 노드들 간의 합의된 규칙을 바꿀 수 있는 과정이 필요하다.

비트코인은 커뮤니티를 통해서 체인을 어떻게 바꾸어나갈지 의논하고 결정한다.
결정된 내용이 코드에 반영되고 네트워크에 반영되는 과정은 꽤나 흥미롭다.

논의하여 곁정된 내용은 각 비트코인 구현체들이 구현을 한다. 이 구현된 내용은
바로 적용하지 않는다. 특정 블록 갯수동안 마이너들은 생성한 블록에 특정한 비트를 사용해서
새로운 업데이트에 찬성하거나 반대한다. 투표기간이 끝나면, 투표기간동안 생성된 블록을 확인한다.
새로운 업데이트의 반영 기준이 90%였다면, 생성된 블록 중 90%의 블록에 찬성 표시가 되어있을 때
해당 기능을 활성화 한다.

기능 업데이트하기 참 힘들다 싶다가도, 사용자들의 동의를 얻어 하는 업데이트란 생각이 든다.
??? 무슨 이야기를 더 할 수 있을까? 이건 무엇을 지키기 위한 구성인걸까?


- 잘 모르겠으면 간단하게만 이야기하고 다른 걸 이야기하자.

## P2P 소프트웨어의 업그레이드 전략

서비스는 계속해서 바뀐다. 개발자들은 프로그램을 꾸준히 변경한다.
온라인 게임이나, 서버를 쓰는 앱 처럼 서버와 클라이언트가 서로 통신하는 서비스는
업데이트 이후에도 문제 없이 통신할 수 있게 주의를 기울여야 한다.
업데이트에 실수가 있다면, 이전 버전의 클라이언트와 나중 버전의 서버가 만났을 때 예상치 못한 버그가 발생할 수 있다.

가장 간단한 업데이트 방법은 통신하는 양쪽의 프로그램을 끄고 전부 업데이트한 다음에 다시 켜는 방법이다.
나는 이전에 모바일 게임을 개발할 때 이 방법을 썼다. 모바일 게임 유저들은 대체로 최신의 클라이언트를 원하기 때문에
강제적으로 버전업을 해도 큰 불만을 가지지 않는다. 행여 서로 다른 버전의 유저들이 겪는 경험이 달라서
게임의 밸런스의 문제가 된다면 해당 문제가 더 큰 문제가 된다.

모바일 앱을 만들 때는 좀 더 보수적이었다. 많은 유저들이 지금 버전에 만족한다.
업데이트를 받으라고 유저를 강요하면, 원치 않은 상황에 앱을 못쓰게 되어서 유저들의 반발이 클 수 있다.
이 경우 통신을 하는 양 단이 이전 버전도 지원하면서 점진적으로 업데이트하게 했다.
코드에는 버전에 따른 if/else문이 들어가거나, API에 옵셔널한 추가적인 인자들이 지속적으로 추가되는 등
코드 관리에 부담이 생기는 방식이다.

p2p로 동작하는 블록체인은 업데이트할 때 신경써야할 부분이 더 많다. 
먼저 무엇을 바꿀지 정하는 것부터가 쉽지 않다. 블록체인 네트워크에 참여하는 사람들은
자신의 이익에 따라 프로그램의 업데이트를 반대할 수도 있다. 코드를 고치기 전, 무엇을 고칠 것이고, 그 영향이
어떻게 될 것인지 충분한 토의가 필요하다. 비트코인과 이더리움은  BIP와 EIP를 통해 변경 사항을 논의 밎 결정하는 과정을 거친다.

프로그램을 수정했어도 바로 해당 사항을 적용할 수 없다. 비트코인과 이더리움 노드를 돌리는
사람들, 수 많은 verifier들이 같이 버전업을 해주어야 한다. 만약 네트워크의 일부만 버전을 올리고 일부는 이전 버전을 쓴다면
큰 문제가 생길 수 있다. 새 버전을 쓰는 사람끼리 하나의 비트코인 네트워크를
구성하고, 이전 버전을 쓰는 사람들끼리 이전 버전의 네트워크를 구성하게 된다. 비트코인을 사용하는 모두가 싫어할 상황이다.

비트코인은 이 문제를 해결하기 위해서 마이너들의 투표 시스템을 도입했다. 마이너들이 블록을 마이닝할 때
버전업을 할 준비가 되어있는지 표시한다. 특정시간동안 찬성에 투표된 블록의 숫자가 충분하면 해당 변경사항이
적용된다. 2017년에 있었던 비트코인의 segwit 업데이트는 특정기간동안
마이너들의 95%가 찬성에 투표했을 때 실행되는 조건을 가지고 있었다. 2017년 7월 조건을 만족시켜
비트코인 네트워크는 segwit을 도입했다.

비트코인에서 변화를 도입하는 조건으로 마이너들의 투표를 쓰는 것도 완벽한 해결책은 아니다.
블록체인에서 마이너들의 해시파워 뿐 아니라 수많은 밸리데이터노드들의 참여 역시 중요하기 때문이다.
하지만 벨리데이터 노드들의 투표를 안전하게 처리할 방법이 없다.
블록체인의 네트워크를 업데이트 하는 해결책은 아직 나오지 않은 것 같다. 더 많은 사람들 논의하고,
더 많은 문제들이 터져서 하나 하나 해 나가면서 방법을 찾지 않을까.


### 51% 공격

PoW 알고리즘이 건강하게 동작하려면 한 세력이 50% 이상의 권력을 가져서는 안된다.
한 세력이 51% 이상의 파워를 가지게 된다면, 다른 모든 세력보다 빠르게 블록을 생성할 수 있다.
51% 이상의 파워를 가지고 있게 되면, 다음과 같은 공격이 가능해진다.
거래소에서 비트코인을 입금하여 USD로 출금한 뒤 거리소에 비트코인을 넣었던 이력을 없앨 수 있다.
(FIXME 51% 어택에 대한 레퍼런스 추가하자.)

블레체인은 분산화를 가치로 뽑지만, 마이닝 업체들은 분산화되어있지 않다.
한 개인 개인이 마이닝하는 것보다, 돈을 많이 들여서 마이닝만 하는 기계를
많이 구매하는 게 더 효율적이기 때문이다. 비트코인 마이닝의 대부분은 거대 마이닝 풀이
하고 있다. 이들이 네트워크에서 부정적인 일을 하지 않는 이유는,
그 대신 꾸준히 비트코인을 채굴하는 것이 더 효율적이기 때문이다.
채굴 보다 문제를 일으키는 게 더 효율적인 날이 온다면 위험하다.
(FIXME 이걸로 충분한 걸까)

마이너들의 독점을 막기 위해서 여러 도구들이 고안되기도 했다.
마이너들은 채굴을 효율적으로 하기 위해서 별도의 칩을 만든다. 이를 ASIC이라고 부른다.
기본적인 방향성은 일반 사용자들의 PC가 ASIC보다 효율적으로 만드는 것이다.
그래픽 카드를 사용하여 병렬적인 연산을 추가한다거나, 메모리를 많이 사용하는 시도뜰이 있다.

51% 공격 때문에 새로 만들어지는 체인들은 PoW를 선택하기가 어렵다.
만약 새로 생긴 체인이 비트코인 마이닝 하는 기계를 조금 수정해서 채굴할 수 있다면,
이미 비트코인을 다량 채굴하던 누군가가 끼어들어 쉽게 51% 공격을 실헝한 뒤 빠져나올 수 있다.
PoW는 초창기 블록체인에는 훌룡한 수단이지만, 지금 들어가기엔 늦었다.
(FIXME 예시 필요)

### 극단적인 liveness

PoW의 특징은 그 극단적 liveness에 있다. 그리고 이는 극단적인 불안함을 만든다.
PoW는 노드가 1개일 때도 블록을 만들 수 있고, 노드가 수천, 수만개일 때도 노드끼리 합의할 수 있는
알고리즘이다. 스케일이 매우 잘 되는 알고리즘이다.
인공지능의 반란으로 모든 지구상의 컴퓨터의 소유권을 잃고, 고물덩어리 컴퓨터 단 한대만 남더라도
해당 컴퓨터로 혼자서 블록을 생성할 수 있다. 이 놀라운 기능에 대한 대가는 불안함이다.
내가 보고 있는 블록이 진실이 아닐 수 있다. 언제든지 누군가 더 멋진 블록을 생성해오면 바뀔 수 있다.
그 어디에도 확실함은 없다. PoW 블록을 믿는 건 일종의 베팅이다. PoW 블록을 사용하는 소프트웨어는
10블록을 만들기 위해 수 천만원이 들기 때문에 이것이 바뀔 리 없어! 같은 류의 가정을 깔고 살아간다.
(혹시 네트워크가 정말 갈라진 적이 있을까?)

### 비트코인에서 안전하게 트랜잭션을 처리하려면

PoW 컨센서스를 사용하는 체인에서 어플리케이션을 만든다는 건 정말 간떨리는 일이다.
나는 개발할 때 확실한 게 좋다. 예전에 Node.js 의 DB 라이브러리를 쓰는데
어떤 에러가 발생할 수 있는지 제대로 명시가 되어있지 않아서 쓸 때 많이 불편했다.
unique 키 에러가 나면 해당 에러만 나는 걸 잡고 싶은데 어떤 형식의 에러가 던져질지 알지 못했다.
내가 잘 모르고 있는 에러 케이스에도 대응하고 싶었는데 문서화가 안되어 있어서 알 수 없었다.
예전에 Java에서 디비 라이브러리도 명시를 안해줘서 고생했었다.
많지 않은 경험이지만 유독 내가 썼던 DDB라이브러리들이 그랬다.

PoW 컨센서스를 쓰는 체인에 100% 확신이란 없다. 내 노드가 알고 있는 best block보다 더 점수가 높은 블록이
갑자기 나타날 수 있다. 


### PoW와 에너지

나는 PoW가 영원할거라 보진 않는다. Proof of work의 work가 무의미하기 때문이다.
우리는 다른 더 의미있는 일을 할 수 있을 전기에너지를 비트코인으로 바꾸고 있다.
비트코인의 신뢰는 이 전기에너지에서부터 온다. 비트코인이 더 많은 인기를 얻을 수록,
비트코인이 더 많은 가치를 가질수록, 더 많은 전기에너지가 필요해진다.
그렇다고 답이 PoS가 될지는 모르겠지만.

### 블록체인과 백섭

나는 로봇 동아리에서 태양광 자동차를 만들었었다.
자동차는 큰 파트라서 각자 자기 파트가 나뉘었는데, 나는 조향부위였다.
자동차가 엄청 무거워서 조향을 위한 모터도 엄청 무겁고 강력한 DC모터를 사용했다.

### Difficulty Adjustment

PoW는 블록의 평균 생성 시간이 일정하도록 관리한다.
하지만 마이너들의 마이닝 파워는 일정하지 않기 때문에 블록을 생성하는 난이도를
꾸준히 조정해야 한다. 그 과정에서 재밌는 일이 발생한다. 

나는 첫 프로그래밍이 로봇 프로그래밍이었다. AVR 칩에 C로 된 프로그램을 넣고
열심히 LED 껐다 켜고, 모터를 돌렸다.

프로그래밍을 공부할 때 한 단계를 건넜다는 느낌이 들 때가 있었다.
변수, 함수, 클래스의 사용에 익숙해지고, 스탠다드 라이브러리와 
third party 라이브러리를 공부해서 이해할 수 있게 되었을 때였다.
영어로 모르는 사람과 대화에 성공할 때와 비슷한 기분이었다.
와 이게 이렇게 되는구나. 그 땐 내가 뭐라도, 뭐든지 짤 수 있을 줄 알았다.
메모리와 저장장치는 내가 명령하는 대로 완벽히 동작했다.

하지만 내가 모든 값을 조절할 수 있는 게 아니다.
로봇을 만든다면, 내가 조절할 수 있는 건 모터에 전달되는 전력이다.
모터에 전달되는 전력과 외부 상황에 따라서 바퀴가 동작하는 속도 달라진다.
일정한 속도로 자동차가 달리기 위해서는 바퀴의 현재 속도를 지속적으로 측정하면서
모터에 들어가는 전력을 조절해야 한다. 이 때 필요한 게 제어다.


* 논문을 첨부할 수 있으면 좋겠다.
* Ethereum 백섭
* difficulty adjustment 
* P2P 소프트웨어를 개발한다는 것은,
* 로그의 

PoW는 ㄲ

pow의 특징
pos의 장점



## Byzantine problem

비잔틴 문제는 풀어야 하는 걸까

## PBFT, Tendermint, Libra Hotspot

CodeChain을 만들 때 팀원별로 분야를 정해서 구현했다. 나는 컨센서스를 맡았다.
컨센서스 중에서도 텐더민트 컨센서스 알고리즘을 구현했다.(코드체인은 PoW 알고리즘도 지원했는데
이 부분은 다른 분이 구현했다.)
아예 바닥부터 짠 건 아니었고, 컨셉수준의 구현이 되어있을 때부터 작업을 시작했다.
몇달의 디버깅, 리팩토링 과정을 통해서 몇 년 째 문제 없는 컨센서스가 코드를 구현했다.

텐더민트 컨센서스는 정해진 수의 위원회에서 2/3이상의 허락을 받는 블록을
체인에 포함시키는 알고리즘이다. 컴퓨팅 파워가 높은 참여자가 블록을 생성하는 PoW 컨센서스와 다르게,
지분을 많이 가진 참여자들이 모여서 블록을 생성하는 PoS 방식에서 주로 사용하는 알고리즘이다.
텐더민트 이외에도 비슷한 알고리즘들이 여럿 있다.

텐더민트 알고리즘의 핵심은 두번의 투표 과정에 있다. 100명의 위원이 서로 돌아가면서 블록을 생성한다고 생각해보자.
한 위원이 블록을 제안하면, 제안한 위원 포함 100명의 위원이 해당 블록을 넣을지 말지 투표한다.
2/3 보다 많은, 즉 67 표 이상의 찬성을 받은 블록이 체인에 포함된다.

내가 처음 텐더민트 알고리즘 읽었을 때 헷갈리는 점 중 하나가 블록에 찬성을 던지는 기준이었다.
각 위원이 자신에게 경제적인 이득을 주는 블록만 넣으러고 하면 블록 생성이 영원히 안될 것 같았다.
텐더민트 알고리즘에서 각 위원들의 경제적인 인센티브는 고려하지 않는다. 모든 위원들은 정해진 규칙을 따라야 한다.
규칙에 맞게 생성된 블록에 항상 찬성 투표를 해야 한다. 위원들의 경제적인 인센티브는 컨센서스 알고리즘 바깥에서
정당한 보상 체계를 만들어서 해결해야 한다.

합의를 하기 위해서 왜 두 번의 투표가 필요할까? 위원들이 직접 사람이고, 만나서 투표할 수 있었다면 한 번의
투표로 블록이 체인에 포함되도록 결정할 수 있을 것이다. 문제는 블록체인은 p2p 소프트웨어이고
누구나 언제든 룰을 악용할 수 있기 때문이다. 네트워크를 통해 받은 모든 메시지든 가짜일 수도 있다.
와야하는 메시지가 안 올 수도 있다. 이런 환경에서 단 두번의 투표로 안정적인 결정을 내릴 수 있다는 게
오히려 더 신기하게 느껴진다.

다만 텐더민트와 비슷한 알고리즘들(앞으로 PBFT 계열 알고리즘이라 하겠다.)은 그 어떤 상황에서도
전체 위원의 2/3보다 많은 노드들이 정상적이라고 가정한다. 이 가정이 깨지면 안전하게 동작하는 방법이 없다.

누가 보냈는지 확인하기 위해서 모든 메시지에는 각 위원들의 서명이 포함된다.
텐더민트 알고리즘에서 첫 번째 투표른 Prevote, 두 번째 투표는 Precommit이라고 부른다.

## 텐더민트의 동작

텐더민트 알고리즘에서 각 참여자들은 다음과 같이 행동한다. 먼저 블록 제안자가 블록을 만들어 제안한다.
블록 제안자가 아닌 위원은 제안된 블록이 규칙에 맞게 생성되었다면 해당 블록에 찬성하는 Prevote 메시지를
네트워크에 뿌린다. 각 노드들은 전체 Prevote중 2/3개 이상의 표를 받을 때까지 기다린다.

Prevote 표를 모았을 때 전체 위원의 2/3 이상이 해당 블록에 찬성했다면 해당 블록에 Precommit 메시지를 보낸다.
전체 Prevote 표 중 2/3 이상 모았는데 한 블록에 대한 찬성이 2/3를 넘지 않았다면 해당 블록을 거절하는 Precommit
메시지를 보낸다.

한 블록에 대해 2/3 이상의 찬성 Precommit을 모으면 해당 블록은 확정된 블록이라고 판단할 수 있다.
2/3 이상의 Precommit 표를 모았을 때 찬성이 2/3가 아니라면 다음 블록 제안자가 이전 블록을 무시하고 새로운 블록을 제안한다.

##

2/3 이상의 찬성 Prevote를 받았을 때 블록을 확정짓지 못하는 이유가 뭘까.
나는 그걸 봤지만, 남은 못봤을 수 있기 때문이다. 100개의 위원 있다고 가정해보자.
그리고 어떤 블록에 대해 67 개의 찬성 Prevote, 33개의 반대 Prevote가 있다고 가정해보자.
(Proposal 블록이 늦게 생성되고, 전파가 잘 안되면 모두가 정직해도 이런 경우가 발생할 수 있다.)
이 때 한 노드가 67 개의 찬성표를 봤다고 하더라도, 다른 노드는 33개의 반대와 34개의 찬성 표를 받을 수도 있다.

모든 표가 언젠가 정해진 시간 안에 도착한다는 보장이 있다면 모두가 100개의 표를 보고 판단할 수 있으므로
투표 한 번으로도 안전할 것이다. 하지만 블록체인 세상은 험난하다. 중간에 몇 노드가 랜선이 끊어져서 패킷을
보내지 못해도 동작해야 한다. 몇 몇 노드는 일부러 표를 안보낼 수도 있다.

따라서 33개의 반대와 34개의 찬성 표를 받은 노드는 모든 표를 받지 못한 상태에서 판단을 내려야 한다.
결국 67개의 찬성을 받은 노드와 (34개의 찬성과 33개의 반대)를 받은 노드는 서로 다른 결정을 내릴 수 밖에 없다.

##

투표를 한 번 더 하면 뭐가 달라질 수 있을까?
투표와 더불어 텐더민트에서 중요한 요소가 락이다. 한 블록에 대해서 2/3 이상의 찬성 Prevote를 본 노드는
그 블록에 락을 잡는다. 앞으로 더 높은 단계의 락이 발생하기 전까지 해당 노드는 락이 걸린 블록에 대해서만
찬성하고 나머지 블록에 대해서는 반대한다.

여기서 락 덕분에 Prevote 스텝 이후에 상황을 간략하게 만들 수 있다.
한 블록에 대해 찬성 Precommit 투표를 한 노드는 해당 블록에 락이 잡혀있다.
블록을 확정지을 수 있는 조건은 2/3 이상의 Precommit 표를 확인하는 것이었다.
락 덕분에 2/3 이상의 Precommit 표를 본 순간, 결국인 모든 노드들이 해당 블록을 확정지을 것이라고 판단할 수 있다.

2/3 이상의 찬성 Precommit 표를 확인했다는 의미는 2/3이상의 노드가 해당 블록에 락을 잡았다는 의미이다.
락이 잡히지 않은 노드들은 1/3 이하이므로 이들은 새로운 락을 만들 수 없다. 결국 2/3 이상의 위원이
락을 잡은 블록에 대해 위원회 전체가 합의하게 된다.

##

회사에서 다른 컨센서스들에 대해서도 공부했었다. 그 중 기억에 남는 게 페이스북이 주도하는
리브라의 컨센서스였다. 큰 틀은 텐더민트와 같다. 리브라 역시 두 번의 투표과정을 통해서 블록을
확정짓는다. 리브라는 Prevote와 Precommit을 나누지 않았다. 블록 제안과 투표, 블록 제안과 투표만을 반복한다.
여기서 재밌는 점은 투표가 이전 블록에 대한 투표까지 포함한다는 점이다. 블록 N번에 대한 투표는
블록 N-1에다 찬성한다는 의미다. 일종의 파이프라인화된 텐더민트라고 볼 수 있다.

리브라가 재밌던 점은 이렇게 파이프라이닝한 구조를 쓴 결과, 알고리즘의 특징을 증명하는 게 더 간단해졌다는
점이었다. 텐더민트를 공부할 때보다 간단하게 알고리즘의 특징을 이해할 수 있었다.

##

구현할 때 고생이 많았다. 네트워크, 블록 생성, 블록 검증, 타임아웃 등  모든 요소가 비동기 동작이었다.
초반엔 변수별로 락을 잡는 멀티쓰레드 코드였다. 꽤 많은 스테이트가 필요해서 데드락이 여기 저기서 발생했다.
다른 팀원분들과 고민 후 싱글 쓰레드에 이벤트를 받아서 처리하는 코드로 고쳤었다. (아마 이부분은 다른 동료분이
하셨던 걸로 기억한다.) 테스트 네트워크 돌리고, 문제 발생하면 여러 노드의 로그들 분석하고, 버그를 고치는 과정을
꽤나 많이 반복했었다. 



두 번 확인하는 이유가 뭘까

한번도 확인 안하면, 각자 당연히 다른 걸 가지겠지.

한 번 확인하면? prevote 메시지만 있다면?

무슨 일이 벌어질까?
proposer가 응답이 없으면? proposer를 일부만 받으면?
propose가 응답이 없어도 잘 동작한다. prevote메시지를 결국 모두가 보내긴 할 것이다.
2/3 이상이 잘 받았다고 말 못하면 다음 뷰로 넘어갈 것이다.

중간에 두 번 투표하는 행동자가 있으면?
뭐가 달라질까?
내가 2/3의 prevote를 봤다는 건 무엇을 의미할까
내가 100개의 표 중에서 67개의 찬성 prevote를 봤어.
그러면 나는 확정되었다고 보지.
다른 사람은 33개의 반대와 34개의 찬성을 봤어. 그러면? 이 노드는 다음 블록을 생성하겠지

precommit은?
락으로 문제를 해결해.
2/3의 결과를 본 노드들은 끝까지 그걸 지켜

precommit 찬성을 66개 보면 왜 안전할까?
락걸린 노드가 소수일 때. 락 걸린 노드가 다수일 때.
프리커밋 67개를 봤다는 의미는 락걸린 노드가 다수일 때를 의미해
그러면 락이 안걸린 노드들이 새로운 락을 만들 수 없어.


또 무슨 일이 있을까.


## state와 immutable data structure 이야기.

나는 하스켈을 좋아하고, immutable한 자료구조의 특징을 좋아한다.
변경했을 때 이전의 값들이 남아 있어서 쉽게 snapshot 기능을 구현할 수 있다는 점이 좋다.
값이 안바뀌기 때문에 쉽게 여러 쓰레드에 공유하기 편한것도 장점이다.
성능 느리다고 싫어하는 사람들도 있던데, 나는 성능 좀 느려도 괜찮다고 생각한다.
정 느리면 제일 느린 몇 몇 부분만 고치면 된다.

이더리움을 공부하다가 State Trie를 만났을 때 반가웠다.
이렇게 유명한 곳에서 쓰고있는 immutable 자료구조라니. 먼 타향에서 만난 고향 친구 같은 느낌이었다.

블록체인의 요구사항과 immutable한 자료구조의 특징이 잘 맞다.
블록체인은 거대한 스테이트를 꾸준히 조금씩 수정한다.
이더리움의 스테이트 트라이는 모든 유저의 이더리움 양, 스마트 컨트랙트의 변수들을 저장하고 있다.
트랜잭션을 하나 하나 실행할 때마다 이 스테이트의 값을 하나 혹은 몇개씩 수정한다.

과거의 데이터도 자주 읽는다. 어플리케이션 입장에서 가장 최신의 블록은 쉽게 바뀔 수 있기 때문에
일부러 과거의 데이터를 읽는다. 블록체인 엔진 입장에서도 과거의 데이터를 자주 읽는다.
PoW에서 과거의 블록에 이어 붙인 블록을 실행하려면, 과거 블록의 데이터를 읽어야 한다.

따라서 전체 데이터는 거대한데, 실시간으로 조금씩 업데이트 되고 있고, 업데이트하기 전 정보도
쉽게 읽을 수 있는 자료구조가 필요하다. 딱 immutable한 트리를 쓰기 좋다.
immutable 트리는 값을 수정할 때 새 트리를 만든다. 하지만 전체 데이터를 복사하는 건 아니고, 대부분의
데이터를 이전 트리에서 재활용한다. 값이 바뀐 노드부터 root까지의 노드만 수정하고 나머지는 그대로 사용할 수 있다.







블록체인에서 
PoW기반의 퍼블릭 체인이라면, 최신 블록은 언제든지 바뀔 수 있기 때문에 일부러
1시간 전에 생성된 잘 안바뀔 블록의 스테이트를 자주 읽는다.


특히 PoW 기반 퍼블릭 블록체인은 가장 최신 블록을 믿을 수 없기 때문에
일부러 약 1시간 전에 만들어진 블록의 정보를 읽는다.

각 블록에서 읽을 수 있는 스테이트를 매번 통째로 디스크에 저장한다면,
감당할 수 없을 정도로 디스크를 많이 사용할 것이다.
immutable한 트리 구조의 자료구조를 사용하면 쉽게 문제를 해결할 수 있다.
immutable한 트리를 수정하면 이전 트리는 그대로에, 변경뙨 사항들과 그들의 부모만 수정된
새로운 트리를 쉽게 만들 수 있다.


현재 데이터 이전 데이터
해시 기반
디프를 보기.
단점?
이게 끝인가?


## DB에 저장하는 Ethereum State Trie

이더리움의 스테이트 트라이를 처음 공부할 때, 잘 이해가 안가던 부분이 있었습니다.
바로 트라이 노드간의 레퍼런스를 어떻게 표현하는지, 그리고 그 연결 부분이 디비에 어떻게 저장되는지였습니다.

트라이는 트리의 한 종류입니다. 이 글에서는 이더리움 스테이트 트라이의 트리적인 특징에 대해
이야기 하겠습니다.

제가 그 때까지 알던 트리를 메모리에서 표현하는 방법은  두가지가 있었습니다. 각 노드를 힙에 할당한 뒤 자식 노드에 대한
포인터를 부모 노드에 저장합니다. 다른 방법은 perfect binary tree에서 각 노드를 어레이에 순서대로
저장하는 방법입니다. 이 방법을 쓰면 index의 연산으로 쉽게 자식 노드를 찾을 수 있습니다.
트리를 디스크에 저장할 때는 메모리의 표현 방식에 상관 없는 방법을 썼습니다. 정렬된 트리였다면 정렬된 원소들을
리스트 형태로 디스크에 저장했습니다. 아니면 트리 구조를 나타낼 수 있는 포맷인 JSON 이나 XML 같은 방법을 쓸 수 있구요.
SQL DB에 저장하는 데이터는 SQL에 저장할 때 생성한 ID를 레퍼런스로 썼습니다.

이더리움 스테이트 트라이는 놀랍게도 자식 노드의 Hash를 레퍼런스로 사용합니다.
메모리에 있을 때도 트라이의 모든 노드를 키밸류 자료구로(해시나 트리)에 저장합니다.
부모 노드는 자식노드의 해시값을 가지고 있어서 자식 노드의 해시를 키로 자식을 찾아옵니다.

트리를 구현하기 위해 또 다른 트리(혹은 해시테이블)을 쓰다니 저에게는 혁명적인 발상이었습니다.
한 번 더 재밌는 건 메모리에서의 표현 방법과 디스크에서의 표현 방법이 동일하다는 점입니다.
디스크에 저장할 때도 Level DB나 Rocks DB같은 key value 스토리지에 각 노드를 저장합니다.
사실상 메모리든 디스크든 구분할 필요가 없습니다.

또 알고보면, 지금 이더리움의 state trie는 일반 컴퓨터의 메모리에 담기엔 너무 큽니다.
자주 접근하는 노드는 메모리의 key value 스토리지에 캐시처럼 저장하고, 자주 안쓰는 데이터는
디스크에서 그때 그때 읽어오는 방법을 씁니다.

저는 항상 트리에서 노드들끼리 연결하는 방식은 디스크에 있을 때와 메모리에 있을 때 서로
다르게 표현될 것이라는 고정관념이 있었습니다. 이 틀에 맞지 않는 구조라 계속 헷갈렸던 거 같네요.

말 안하고 넘어가면 아쉬우니 하나 추가하자면, 이렇게 자식 노드의 해시를 노드의 포인터로 취급하여 같이 저장하기 때문에,
최상위 부모 노드의 해시는 트리 전체의 해시를 한 것과 같습니다. 아마 이 특징을 얻기 위해서
해시 값을 포인터로 쓴 것이라고 생각합니다. 블록체인에서 전체 상태의 해시값을 구하는 건 중요하니까요.

## Log structured sorted merge tree

내가 코드를 읽었던 블록체인 구현체들은 대체로 Log-structured merge-tree(LSM Tree) 기반의 key value 디비를 사용했다.
비트코인 코어는 LevelDB를 사용한다. 이더리움의 Go언어 구현체도 LevelDB를 사용한다.
Parity 이더리움(지금은 OpenEthereum)은 RocksDB를 사용한다. Cosmos도 LevelDB를 사용한다.

처음에는 RocksDB와 LevelDB가 SQL을 지원하지 않는 Key-Value형 DB라서 NoSQL들이 쓰는 자료구조인줄 알았다.
좀 더 찾아봤더니 SQL이든, NoSQL이든 상관없이 쓸 수 있는 자료구조였다.
내가 이전 프로젝트에서 썼던 elastic search도 LSM Tree를 쓰고 있었다.
MySQL에도 InnoDB대신 MyRocks는 스토리지 엔진을 사용하면 LSM Tree를 사용할 수 있다.
LSM Tree는 흔히 SQL 디비에서 사용하는 B-Tree에 대응되는 자료구조로 이해하면 된다.

B-Tree나 LSM Tree나 사용하는 곳마다 세부사항이 다를 것이다. 나는 PostgreSQL에서 사용하는
B-Tree와 RocksDB에서 사용하는 LSM Tree를 기준으로 이야기 하겠다.

LSM Tree는 B-Tree에 비해 쓰기 속도가 빠르다. 대신 읽기는 더 느리다.

B-Tree에 비해서 LSM Tree는 꽤 복잡하다. 크게 봐서 3가지 방식으로 데이터를 관리한다.
하나는 메모리에 있는 MemTable, 다른 하나는 메모리에 있는 데이터를 로그 형식으로 일렬로 적는
WAL(Write ahead log), persistant하게 데이터를 보관하는 SST(Sorted String Table)이 있다.

LSM-Tree는 데이터를 빠르게 쓰는데 진심이다. 어떤 세부사항을 보더라도 쓰기 속도를 빠르게 하겠다는
결정이 눈에 보인다.
LSM-Tree는 데이터를 더 빠르게 쓰려고 노력한 흔적이 많이 보인다.

첫 번째 노력은 MemTable과 WAL파일이다. 디스크에 가장 빠르게 데이터를 쓰는 방법은 뭘까.
sequential하게 쓰는 것이다. 모든 쓰기 동작은 하나의 파일에 sequential하게 데이터들 적는다.
당연히 sequential한 데이터는 읽기가 힘들기 때문에 WAL파일에 있는 데이터를 메모리에서 쉽게
접근할 수 있게 MemTable을 사용한다.

MemTable은 최근에 쓴 데이터들을 빠르게 읽는 캐시 역할을 한다. RocksDB는 MemTable에 Skip list를 사용한다.
[^1] Skip list는 O(log n)에 값을 읽을 수 있고, O(log n)에 값을 쓸 수 있다. 또한 동시에 값을 쓸 수 있다.

두 번째 노력은 SST의 관리 방식에 있다. LSM Tree는 SST파일을 관리할 때 항상 sequential한 쓰기만 한다.
random한 쓰기를 하지 않는다. sequential한 쓰기가 random 쓰기보다 빠르기 때문이다.[^2]
MemTable과 WAL 파일에 쓴 데이터는 크기가 커지면 SST 파일을 만들어 디스크에 저장한다.

[^1]: RocksDB는 MemTable에서 사용하는 자료구조로 Skip list대신 다른 걸 선택할 수 있다. Skip list가 기본값이다.
[^2]: SSD는 하드 디스크에 비해서 random 쓰기가 빠르지만, SSD 역시 sequential 쓰기가 random 쓰기보다 빠르다. 페이지 단위로 쓰기와, 이전 페이지 가비지 처리 때문이다.

LSM Tree에서 M은 Merge를 의미한다. Merge가 없을 때를 먼저 생각해보자.
SST 파일은 key 기준으로 정렬되어 있다. SST 파일은 파일 안에 적힌 데이터의 시작 key와 끝 key의 정보가 있다. 여러 SST 파일들 사이에 키 범위는 겹칠 수 있다. 따라서 적절한 merge를 하지 않는다면,
하나의 키를 찾기 위해 모든 SST 파일을 열어봐야할 것이다.

LSM Tree는 적절한 Merge 과정을(Compaction 이라고도 부른다)  통해서 SST 파일을 합친다. SST 파일을 합치는 과정은 익숙한 merge sort의 그 방법을 쓸 수 있다. 중요한 점은 언제 어떤 SST 파일들을 골라서 merge할 것인가다.
이 Merge를 잘 해야 O(log n)에 데이터를 조회할 수 있다.
Rocks DB는 두 가지 Compaction 방법을 쓴다. 그 중 Leveld Compaction[^3]의 동작원리를 보자.

Leveld Compaction은 SST 파일들을 여러 레벨로 구분한다. 한 레벨의 SST 파일들은 전체 key 범위를 커버한다.
한 레벨의 SST 파일들은 서로 키가 겹치지 않는다. 높은 레벨은 낮은 레벨보다 n배 더 많은 크기의 값을 가진다. 데이터의 갯수가 _m_이라고 할 때 레벨의 갯수는 _log m_ 이다.
한 레벨의 SST 파일들끼리 키가 겹치지 않는 특징 때문에 데이터를 찾기 위해서 level 갯수 만큼만 쿼리하면 된다. 따라서 O(log n)의 시간 안에 데이터를 찾을 수 있다.

데이터를 찾는 과정이 복잡하기 때문에 한 번 더 설명하자면, 다음 과정을 거친다.
먼저 MemTable에서 찾는다. 없으면 Level 

레벨은 0부터 시작하며, 레벨 별로 한계 디스크 사이즈를 설정한다




[^3]: https://github.com/facebook/rocksdb/wiki/Leveled-Compaction



### bloom filter
### 여러 곳에 파일이 있을때
### 디비 버전이 달라서 Bitcoin fork 이야기




## bloom filter

블룸필

## DB 이야기



## 여러 체인이 소통하기. 어떻게 상대방을 믿을까

## sequence와 UTXO 둘다 앱만들기는 어렵다.
