# Consensus

프로그래머로서 블록체인의 핵심은 합의라고 생각한다. 여러 합의 방법이 있을 수 있지만,
그 중 가장 잘 동작하고 있는 방식은 PoW라고 생각한다.

PoW는 블록체인 네트워크에 참여한 모든 컴퓨터들이 각자 랜덤한 숫자를 끊임 없이 계산한다.
각 숫자마다 점수가 있어서, 해당 차례에 필요한 최소 점수보다 높은 점수를 계산하는 컴퓨터가
다음 블록을 생성할 권리를 얻는다.

## 경제적인 알고리즘

PoW으로 합의하는 방식은 그 전까지 내가 생각하던 알고리즘과 달랐다. 내가 생각하는 알고리즘은
내가 전지적인 지적 설계자가 되어서 모든 요소들의 트레이드오프를 고려한 뒤 적절한 방식을 결정했다.
PoW는 다르다. PoW가 잘 동작하려면, 한 노드가 생성한 블록이 전체 네트워크에 잘 퍼져야 한다.
과연 한 노드 작성한 블록을 다른 노드들이 전세계 네트워크에 잘 퍼뜨려 줄까?

블록체인 분야에서 재밌고, 또한 어려운 점은, 컴퓨터가 경제적인 주체라는 점이다. 나는 로봇도 만들어 봤고,
게임도 만들어봤고, 앱도 만들어봤지만, 아직까지 컴퓨터가 경제적인 주체라는 점은 고려해본 적이 없었다.
로봇은 내가 명령한 대로만 움직였다. 게임은 간혹 사람들이 해킹을 시도했긴 했지만, 해당 행동은 찾아서 막아야 했다.
블록체인에서는, 의사소통하는 규칙만 맞으면 세부적인 동작 방식은 자유로웠다.
내 노드가 생성한 블록을 다른 노드에 전달할지 말지는 다른 노드의 자유란 의미다. 누구든지 소스코드를
수정해서 다른 동작을 만들어도 괜찮은 동네다.

PoW에서 다른 노드가 생성한 블록을 퍼뜨리는 이유는, 그것이 경제적으로 이득이 되기 때문이다.
내가 생성하게될 미래의 블록의 점수는 해당 블록이 쌓아온 모든 역사를 포함하는 점수다.
따라서 다른 사람이 만든 하나라도 높은 블록 위에 내 블록을 쌓는 것이 이득이다.
또한 그 다른 사람이 만든 블록이 전체 네트워크에 잘 알려져야 한다.

블록체인 업계에서 공부하다 보면, 경제적인 인센티브를 고려하는 많은 서비스들을 볼 수 있다.
서비스들이 이야기하는 알고리즘들을 공부하고, 이해하려고 하다 보면, 경제적인 부분에서 막힐 때가 많다.
정말 모두 의도한 대로 이득을 찾아 행동할까? 코너케이스로 나쁜 찟 하는게 이득이면 어떡하지.
경제적 인센티브의 예외사항들은 어떻게 찾아야하나.

## 분산화

블록체인을 처음 공부할 때 분산화의 개념이 쉬이 이해되지 않았다.
중앙에서 관리하는 개인 혹은 단체가 없다는 말 자체는 의미를 알 수 있었다.
그렇다면 분산화 된 프로그램에서 문제가 생겼을 때 어떤 일이 일어나는지 궁금했다.
게임은 문제가 생기면 디비 데이터를 되돌릴 수 있다. 누군가 주도권을 가지고 있지 않다면
문제가 생겼을 때 어떻게 해야하는가.

가장 간단하게 생각해보면 처음부터 문제가 없는 규칙을 만들면 된다. 우리 모두 알고 있듯이,
처음부터 완벽한 걸 만들 수 없다. 분산화된 노드들 간의 합의된 규칙을 바꿀 수 있는 과정이 필요하다.

비트코인은 커뮤니티를 통해서 체인을 어떻게 바꾸어나갈지 의논하고 결정한다.
결정된 내용이 코드에 반영되고 네트워크에 반영되는 과정은 꽤나 흥미롭다.

논의하여 곁정된 내용은 각 비트코인 구현체들이 구현을 한다. 이 구현된 내용은
바로 적용하지 않는다. 특정 블록 갯수동안 마이너들은 생성한 블록에 특정한 비트를 사용해서
새로운 업데이트에 찬성하거나 반대한다. 투표기간이 끝나면, 투표기간동안 생성된 블록을 확인한다.
새로운 업데이트의 반영 기준이 90%였다면, 생성된 블록 중 90%의 블록에 찬성 표시가 되어있을 때
해당 기능을 활성화 한다.

기능 업데이트하기 참 힘들다 싶다가도, 사용자들의 동의를 얻어 하는 업데이트란 생각이 든다.
??? 무슨 이야기를 더 할 수 있을까? 이건 무엇을 지키기 위한 구성인걸까?


- 잘 모르겠으면 간단하게만 이야기하고 다른 걸 이야기하자.

## P2P 소프트웨어의 업그레이드 전략

서비스는 계속해서 바뀐다. 개발자들은 프로그램을 꾸준히 변경한다.
온라인 게임이나, 서버를 쓰는 앱 처럼 서버와 클라이언트가 서로 통신하는 서비스는
업데이트 이후에도 문제 없이 통신할 수 있게 주의를 기울여야 한다.
업데이트에 실수가 있다면, 이전 버전의 클라이언트와 나중 버전의 서버가 만났을 때 예상치 못한 버그가 발생할 수 있다.

가장 간단한 업데이트 방법은 통신하는 양쪽의 프로그램을 끄고 전부 업데이트한 다음에 다시 켜는 방법이다.
나는 이전에 모바일 게임을 개발할 때 이 방법을 썼다. 모바일 게임 유저들은 대체로 최신의 클라이언트를 원하기 때문에
강제적으로 버전업을 해도 큰 불만을 가지지 않는다. 행여 서로 다른 버전의 유저들이 겪는 경험이 달라서
게임의 밸런스의 문제가 된다면 해당 문제가 더 큰 문제가 된다.

모바일 앱을 만들 때는 좀 더 보수적이었다. 많은 유저들이 지금 버전에 만족한다.
업데이트를 받으라고 유저를 강요하면, 원치 않은 상황에 앱을 못쓰게 되어서 유저들의 반발이 클 수 있다.
이 경우 통신을 하는 양 단이 이전 버전도 지원하면서 점진적으로 업데이트하게 했다.
코드에는 버전에 따른 if/else문이 들어가거나, API에 옵셔널한 추가적인 인자들이 지속적으로 추가되는 등
코드 관리에 부담이 생기는 방식이다.

p2p로 동작하는 블록체인은 업데이트할 때 신경써야할 부분이 더 많다. 
먼저 무엇을 바꿀지 정하는 것부터가 쉽지 않다. 블록체인 네트워크에 참여하는 사람들은
자신의 이익에 따라 프로그램의 업데이트를 반대할 수도 있다. 코드를 고치기 전, 무엇을 고칠 것이고, 그 영향이
어떻게 될 것인지 충분한 토의가 필요하다. 비트코인과 이더리움은  BIP와 EIP를 통해 변경 사항을 논의 밎 결정하는 과정을 거친다.

프로그램을 수정했어도 바로 해당 사항을 적용할 수 없다. 비트코인과 이더리움 노드를 돌리는
사람들, 수 많은 verifier들이 같이 버전업을 해주어야 한다. 만약 네트워크의 일부만 버전을 올리고 일부는 이전 버전을 쓴다면
큰 문제가 생길 수 있다. 새 버전을 쓰는 사람끼리 하나의 비트코인 네트워크를
구성하고, 이전 버전을 쓰는 사람들끼리 이전 버전의 네트워크를 구성하게 된다. 비트코인을 사용하는 모두가 싫어할 상황이다.

비트코인은 이 문제를 해결하기 위해서 마이너들의 투표 시스템을 도입했다. 마이너들이 블록을 마이닝할 때
버전업을 할 준비가 되어있는지 표시한다. 특정시간동안 찬성에 투표된 블록의 숫자가 충분하면 해당 변경사항이
적용된다. 2017년에 있었던 비트코인의 segwit 업데이트는 특정기간동안
마이너들의 95%가 찬성에 투표했을 때 실행되는 조건을 가지고 있었다. 2017년 7월 조건을 만족시켜
비트코인 네트워크는 segwit을 도입했다.

비트코인에서 변화를 도입하는 조건으로 마이너들의 투표를 쓰는 것도 완벽한 해결책은 아니다.
블록체인에서 마이너들의 해시파워 뿐 아니라 수많은 밸리데이터노드들의 참여 역시 중요하기 때문이다.
하지만 벨리데이터 노드들의 투표를 안전하게 처리할 방법이 없다.
블록체인의 네트워크를 업데이트 하는 해결책은 아직 나오지 않은 것 같다. 더 많은 사람들 논의하고,
더 많은 문제들이 터져서 하나 하나 해 나가면서 방법을 찾지 않을까.


### 51% 공격

PoW 알고리즘이 건강하게 동작하려면 한 세력이 50% 이상의 권력을 가져서는 안된다.
한 세력이 51% 이상의 파워를 가지게 된다면, 다른 모든 세력보다 빠르게 블록을 생성할 수 있다.
51% 이상의 파워를 가지고 있게 되면, 다음과 같은 공격이 가능해진다.
거래소에서 비트코인을 입금하여 USD로 출금한 뒤 거리소에 비트코인을 넣었던 이력을 없앨 수 있다.
(FIXME 51% 어택에 대한 레퍼런스 추가하자.)

블레체인은 분산화를 가치로 뽑지만, 마이닝 업체들은 분산화되어있지 않다.
한 개인 개인이 마이닝하는 것보다, 돈을 많이 들여서 마이닝만 하는 기계를
많이 구매하는 게 더 효율적이기 때문이다. 비트코인 마이닝의 대부분은 거대 마이닝 풀이
하고 있다. 이들이 네트워크에서 부정적인 일을 하지 않는 이유는,
그 대신 꾸준히 비트코인을 채굴하는 것이 더 효율적이기 때문이다.
채굴 보다 문제를 일으키는 게 더 효율적인 날이 온다면 위험하다.
(FIXME 이걸로 충분한 걸까)

마이너들의 독점을 막기 위해서 여러 도구들이 고안되기도 했다.
마이너들은 채굴을 효율적으로 하기 위해서 별도의 칩을 만든다. 이를 ASIC이라고 부른다.
기본적인 방향성은 일반 사용자들의 PC가 ASIC보다 효율적으로 만드는 것이다.
그래픽 카드를 사용하여 병렬적인 연산을 추가한다거나, 메모리를 많이 사용하는 시도뜰이 있다.

51% 공격 때문에 새로 만들어지는 체인들은 PoW를 선택하기가 어렵다.
만약 새로 생긴 체인이 비트코인 마이닝 하는 기계를 조금 수정해서 채굴할 수 있다면,
이미 비트코인을 다량 채굴하던 누군가가 끼어들어 쉽게 51% 공격을 실헝한 뒤 빠져나올 수 있다.
PoW는 초창기 블록체인에는 훌룡한 수단이지만, 지금 들어가기엔 늦었다.
(FIXME 예시 필요)

### 극단적인 liveness

PoW의 특징은 그 극단적 liveness에 있다. 그리고 이는 극단적인 불안함을 만든다.
PoW는 노드가 1개일 때도 블록을 만들 수 있고, 노드가 수천, 수만개일 때도 노드끼리 합의할 수 있는
알고리즘이다. 스케일이 매우 잘 되는 알고리즘이다.
인공지능의 반란으로 모든 지구상의 컴퓨터의 소유권을 잃고, 고물덩어리 컴퓨터 단 한대만 남더라도
해당 컴퓨터로 혼자서 블록을 생성할 수 있다. 이 놀라운 기능에 대한 대가는 불안함이다.
내가 보고 있는 블록이 진실이 아닐 수 있다. 언제든지 누군가 더 멋진 블록을 생성해오면 바뀔 수 있다.
그 어디에도 확실함은 없다. PoW 블록을 믿는 건 일종의 베팅이다. PoW 블록을 사용하는 소프트웨어는
10블록을 만들기 위해 수 천만원이 들기 때문에 이것이 바뀔 리 없어! 같은 류의 가정을 깔고 살아간다.
(혹시 네트워크가 정말 갈라진 적이 있을까?)

### 비트코인에서 안전하게 트랜잭션을 처리하려면

PoW 컨센서스를 사용하는 체인에서 어플리케이션을 만든다는 건 정말 간떨리는 일이다.
나는 개발할 때 확실한 게 좋다. 예전에 Node.js 의 DB 라이브러리를 쓰는데
어떤 에러가 발생할 수 있는지 제대로 명시가 되어있지 않아서 쓸 때 많이 불편했다.
unique 키 에러가 나면 해당 에러만 나는 걸 잡고 싶은데 어떤 형식의 에러가 던져질지 알지 못했다.
내가 잘 모르고 있는 에러 케이스에도 대응하고 싶었는데 문서화가 안되어 있어서 알 수 없었다.
예전에 Java에서 디비 라이브러리도 명시를 안해줘서 고생했었다.
많지 않은 경험이지만 유독 내가 썼던 DDB라이브러리들이 그랬다.

PoW 컨센서스를 쓰는 체인에 100% 확신이란 없다. 내 노드가 알고 있는 best block보다 더 점수가 높은 블록이
갑자기 나타날 수 있다. 


### PoW와 에너지

나는 PoW가 영원할거라 보진 않는다. Proof of work의 work가 무의미하기 때문이다.
우리는 다른 더 의미있는 일을 할 수 있을 전기에너지를 비트코인으로 바꾸고 있다.
비트코인의 신뢰는 이 전기에너지에서부터 온다. 비트코인이 더 많은 인기를 얻을 수록,
비트코인이 더 많은 가치를 가질수록, 더 많은 전기에너지가 필요해진다.
그렇다고 답이 PoS가 될지는 모르겠지만.

### 블록체인과 백섭

나는 로봇 동아리에서 태양광 자동차를 만들었었다.
자동차는 큰 파트라서 각자 자기 파트가 나뉘었는데, 나는 조향부위였다.
자동차가 엄청 무거워서 조향을 위한 모터도 엄청 무겁고 강력한 DC모터를 사용했다.

### Difficulty Adjustment

PoW는 블록의 평균 생성 시간이 일정하도록 관리한다.
하지만 마이너들의 마이닝 파워는 일정하지 않기 때문에 블록을 생성하는 난이도를
꾸준히 조정해야 한다. 그 과정에서 재밌는 일이 발생한다. 

나는 첫 프로그래밍이 로봇 프로그래밍이었다. AVR 칩에 C로 된 프로그램을 넣고
열심히 LED 껐다 켜고, 모터를 돌렸다.

프로그래밍을 공부할 때 한 단계를 건넜다는 느낌이 들 때가 있었다.
변수, 함수, 클래스의 사용에 익숙해지고, 스탠다드 라이브러리와 
third party 라이브러리를 공부해서 이해할 수 있게 되었을 때였다.
영어로 모르는 사람과 대화에 성공할 때와 비슷한 기분이었다.
와 이게 이렇게 되는구나. 그 땐 내가 뭐라도, 뭐든지 짤 수 있을 줄 알았다.
메모리와 저장장치는 내가 명령하는 대로 완벽히 동작했다.

하지만 내가 모든 값을 조절할 수 있는 게 아니다.
로봇을 만든다면, 내가 조절할 수 있는 건 모터에 전달되는 전력이다.
모터에 전달되는 전력과 외부 상황에 따라서 바퀴가 동작하는 속도 달라진다.
일정한 속도로 자동차가 달리기 위해서는 바퀴의 현재 속도를 지속적으로 측정하면서
모터에 들어가는 전력을 조절해야 한다. 이 때 필요한 게 제어다.


* 논문을 첨부할 수 있으면 좋겠다.
* Ethereum 백섭
* difficulty adjustment 
* P2P 소프트웨어를 개발한다는 것은,
* 로그의 

PoW는 ㄲ

pow의 특징
pos의 장점



## Byzantine problem

비잔틴 문제는 풀어야 하는 걸까

## PBFT, Tendermint, Libra Hotspot

CodeChain을 만들 때 팀원별로 분야를 정해서 구현했다. 나는 컨센서스를 맡았다.
컨센서스 중에서도 텐더민트 컨센서스 알고리즘을 구현했다.(코드체인은 PoW 알고리즘도 지원했는데
이 부분은 다른 분이 구현했다.)
아예 바닥부터 짠 건 아니었고, 컨셉수준의 구현이 되어있을 때부터 작업을 시작했다.
몇달의 디버깅, 리팩토링 과정을 통해서 몇 년 째 문제 없는 컨센서스가 코드를 구현했다.

텐더민트 컨센서스는 정해진 수의 위원회에서 2/3이상의 허락을 받는 블록을
체인에 포함시키는 알고리즘이다. 컴퓨팅 파워가 높은 참여자가 블록을 생성하는 PoW 컨센서스와 다르게,
지분을 많이 가진 참여자들이 모여서 블록을 생성하는 PoS 방식에서 주로 사용하는 알고리즘이다.
텐더민트 이외에도 비슷한 알고리즘들이 여럿 있다.

텐더민트 알고리즘의 핵심은 두번의 투표 과정에 있다. 100명의 위원이 서로 돌아가면서 블록을 생성한다고 생각해보자.
한 위원이 블록을 제안하면, 제안한 위원 포함 100명의 위원이 해당 블록을 넣을지 말지 투표한다.
2/3 보다 많은, 즉 67 표 이상의 찬성을 받은 블록이 체인에 포함된다.

내가 처음 텐더민트 알고리즘 읽었을 때 헷갈리는 점 중 하나가 블록에 찬성을 던지는 기준이었다.
각 위원이 자신에게 경제적인 이득을 주는 블록만 넣으러고 하면 블록 생성이 영원히 안될 것 같았다.
텐더민트 알고리즘에서 각 위원들의 경제적인 인센티브는 고려하지 않는다. 모든 위원들은 정해진 규칙을 따라야 한다.
규칙에 맞게 생성된 블록에 항상 찬성 투표를 해야 한다. 위원들의 경제적인 인센티브는 컨센서스 알고리즘 바깥에서
정당한 보상 체계를 만들어서 해결해야 한다.

합의를 하기 위해서 왜 두 번의 투표가 필요할까? 위원들이 직접 사람이고, 만나서 투표할 수 있었다면 한 번의
투표로 블록이 체인에 포함되도록 결정할 수 있을 것이다. 문제는 블록체인은 p2p 소프트웨어이고
누구나 언제든 룰을 악용할 수 있기 때문이다. 네트워크를 통해 받은 모든 메시지든 가짜일 수도 있다.
와야하는 메시지가 안 올 수도 있다. 이런 환경에서 단 두번의 투표로 안정적인 결정을 내릴 수 있다는 게
오히려 더 신기하게 느껴진다.

다만 텐더민트와 비슷한 알고리즘들(앞으로 PBFT 계열 알고리즘이라 하겠다.)은 그 어떤 상황에서도
전체 위원의 2/3보다 많은 노드들이 정상적이라고 가정한다. 이 가정이 깨지면 안전하게 동작하는 방법이 없다.

누가 보냈는지 확인하기 위해서 모든 메시지에는 각 위원들의 서명이 포함된다.
텐더민트 알고리즘에서 첫 번째 투표른 Prevote, 두 번째 투표는 Precommit이라고 부른다.

## 텐더민트의 동작

텐더민트 알고리즘에서 각 참여자들은 다음과 같이 행동한다. 먼저 블록 제안자가 블록을 만들어 제안한다.
블록 제안자가 아닌 위원은 제안된 블록이 규칙에 맞게 생성되었다면 해당 블록에 찬성하는 Prevote 메시지를
네트워크에 뿌린다. 각 노드들은 전체 Prevote중 2/3개 이상의 표를 받을 때까지 기다린다.

Prevote 표를 모았을 때 전체 위원의 2/3 이상이 해당 블록에 찬성했다면 해당 블록에 Precommit 메시지를 보낸다.
전체 Prevote 표 중 2/3 이상 모았는데 한 블록에 대한 찬성이 2/3를 넘지 않았다면 해당 블록을 거절하는 Precommit
메시지를 보낸다.

한 블록에 대해 2/3 이상의 찬성 Precommit을 모으면 해당 블록은 확정된 블록이라고 판단할 수 있다.
2/3 이상의 Precommit 표를 모았을 때 찬성이 2/3가 아니라면 다음 블록 제안자가 이전 블록을 무시하고 새로운 블록을 제안한다.

##

2/3 이상의 찬성 Prevote를 받았을 때 블록을 확정짓지 못하는 이유가 뭘까.
나는 그걸 봤지만, 남은 못봤을 수 있기 때문이다. 100개의 위원 있다고 가정해보자.
그리고 어떤 블록에 대해 67 개의 찬성 Prevote, 33개의 반대 Prevote가 있다고 가정해보자.
(Proposal 블록이 늦게 생성되고, 전파가 잘 안되면 모두가 정직해도 이런 경우가 발생할 수 있다.)
이 때 한 노드가 67 개의 찬성표를 봤다고 하더라도, 다른 노드는 33개의 반대와 34개의 찬성 표를 받을 수도 있다.

모든 표가 언젠가 정해진 시간 안에 도착한다는 보장이 있다면 모두가 100개의 표를 보고 판단할 수 있으므로
투표 한 번으로도 안전할 것이다. 하지만 블록체인 세상은 험난하다. 중간에 몇 노드가 랜선이 끊어져서 패킷을
보내지 못해도 동작해야 한다. 몇 몇 노드는 일부러 표를 안보낼 수도 있다.

따라서 33개의 반대와 34개의 찬성 표를 받은 노드는 모든 표를 받지 못한 상태에서 판단을 내려야 한다.
결국 67개의 찬성을 받은 노드와 (34개의 찬성과 33개의 반대)를 받은 노드는 서로 다른 결정을 내릴 수 밖에 없다.

##

투표를 한 번 더 하면 뭐가 달라질 수 있을까?
투표와 더불어 텐더민트에서 중요한 요소가 락이다. 한 블록에 대해서 2/3 이상의 찬성 Prevote를 본 노드는
그 블록에 락을 잡는다. 앞으로 더 높은 단계의 락이 발생하기 전까지 해당 노드는 락이 걸린 블록에 대해서만
찬성하고 나머지 블록에 대해서는 반대한다.

여기서 락 덕분에 Prevote 스텝 이후에 상황을 간략하게 만들 수 있다.
한 블록에 대해 찬성 Precommit 투표를 한 노드는 해당 블록에 락이 잡혀있다.
블록을 확정지을 수 있는 조건은 2/3 이상의 Precommit 표를 확인하는 것이었다.
락 덕분에 2/3 이상의 Precommit 표를 본 순간, 결국인 모든 노드들이 해당 블록을 확정지을 것이라고 판단할 수 있다.

2/3 이상의 찬성 Precommit 표를 확인했다는 의미는 2/3이상의 노드가 해당 블록에 락을 잡았다는 의미이다.
락이 잡히지 않은 노드들은 1/3 이하이므로 이들은 새로운 락을 만들 수 없다. 결국 2/3 이상의 위원이
락을 잡은 블록에 대해 위원회 전체가 합의하게 된다.

##

회사에서 다른 컨센서스들에 대해서도 공부했었다. 그 중 기억에 남는 게 페이스북이 주도하는
리브라의 컨센서스였다. 큰 틀은 텐더민트와 같다. 리브라 역시 두 번의 투표과정을 통해서 블록을
확정짓는다. 리브라는 Prevote와 Precommit을 나누지 않았다. 블록 제안과 투표, 블록 제안과 투표만을 반복한다.
여기서 재밌는 점은 투표가 이전 블록에 대한 투표까지 포함한다는 점이다. 블록 N번에 대한 투표는
블록 N-1에다 찬성한다는 의미다. 일종의 파이프라인화된 텐더민트라고 볼 수 있다.

리브라가 재밌던 점은 이렇게 파이프라이닝한 구조를 쓴 결과, 알고리즘의 특징을 증명하는 게 더 간단해졌다는
점이었다. 텐더민트를 공부할 때보다 간단하게 알고리즘의 특징을 이해할 수 있었다.

##

구현할 때 고생이 많았다. 네트워크, 블록 생성, 블록 검증, 타임아웃 등  모든 요소가 비동기 동작이었다.
초반엔 변수별로 락을 잡는 멀티쓰레드 코드였다. 꽤 많은 스테이트가 필요해서 데드락이 여기 저기서 발생했다.
다른 팀원분들과 고민 후 싱글 쓰레드에 이벤트를 받아서 처리하는 코드로 고쳤었다. (아마 이부분은 다른 동료분이
하셨던 걸로 기억한다.) 테스트 네트워크 돌리고, 문제 발생하면 여러 노드의 로그들 분석하고, 버그를 고치는 과정을
꽤나 많이 반복했었다. 



두 번 확인하는 이유가 뭘까

한번도 확인 안하면, 각자 당연히 다른 걸 가지겠지.

한 번 확인하면? prevote 메시지만 있다면?

무슨 일이 벌어질까?
proposer가 응답이 없으면? proposer를 일부만 받으면?
propose가 응답이 없어도 잘 동작한다. prevote메시지를 결국 모두가 보내긴 할 것이다.
2/3 이상이 잘 받았다고 말 못하면 다음 뷰로 넘어갈 것이다.

중간에 두 번 투표하는 행동자가 있으면?
뭐가 달라질까?
내가 2/3의 prevote를 봤다는 건 무엇을 의미할까
내가 100개의 표 중에서 67개의 찬성 prevote를 봤어.
그러면 나는 확정되었다고 보지.
다른 사람은 33개의 반대와 34개의 찬성을 봤어. 그러면? 이 노드는 다음 블록을 생성하겠지

precommit은?
락으로 문제를 해결해.
2/3의 결과를 본 노드들은 끝까지 그걸 지켜

precommit 찬성을 66개 보면 왜 안전할까?
락걸린 노드가 소수일 때. 락 걸린 노드가 다수일 때.
프리커밋 67개를 봤다는 의미는 락걸린 노드가 다수일 때를 의미해
그러면 락이 안걸린 노드들이 새로운 락을 만들 수 없어.


또 무슨 일이 있을까.


## state와 immutable data structure 이야기.

나는 하스켈을 좋아하고, immutable한 자료구조의 특징을 좋아한다.
변경했을 때 이전의 값들이 남아 있어서 쉽게 snapshot 기능을 구현할 수 있다는 점이 좋다.
값이 안바뀌기 때문에 쉽게 여러 쓰레드에 공유하기 편한것도 장점이다.
성능 느리다고 싫어하는 사람들도 있던데, 나는 성능 좀 느려도 괜찮다고 생각한다.
정 느리면 제일 느린 몇 몇 부분만 고치면 된다.

이더리움을 공부하다가 State Trie를 만났을 때 반가웠다.
이렇게 유명한 곳에서 쓰고있는 immutable 자료구조라니. 먼 타향에서 만난 고향 친구 같은 느낌이었다.

블록체인의 요구사항과 immutable한 자료구조의 특징이 잘 맞다.
블록체인은 거대한 스테이트를 꾸준히 조금씩 수정한다.
이더리움의 스테이트 트라이는 모든 유저의 이더리움 양, 스마트 컨트랙트의 변수들을 저장하고 있다.
트랜잭션을 하나 하나 실행할 때마다 이 스테이트의 값을 하나 혹은 몇개씩 수정한다.

과거의 데이터도 자주 읽는다. 어플리케이션 입장에서 가장 최신의 블록은 쉽게 바뀔 수 있기 때문에
일부러 과거의 데이터를 읽는다. 블록체인 엔진 입장에서도 과거의 데이터를 자주 읽는다.
PoW에서 과거의 블록에 이어 붙인 블록을 실행하려면, 과거 블록의 데이터를 읽어야 한다.

따라서 전체 데이터는 거대한데, 실시간으로 조금씩 업데이트 되고 있고, 업데이트하기 전 정보도
쉽게 읽을 수 있는 자료구조가 필요하다. 딱 immutable한 트리를 쓰기 좋다.
immutable 트리는 값을 수정할 때 새 트리를 만든다. 하지만 전체 데이터를 복사하는 건 아니고, 대부분의
데이터를 이전 트리에서 재활용한다. 값이 바뀐 노드부터 root까지의 노드만 수정하고 나머지는 그대로 사용할 수 있다.







블록체인에서 
PoW기반의 퍼블릭 체인이라면, 최신 블록은 언제든지 바뀔 수 있기 때문에 일부러
1시간 전에 생성된 잘 안바뀔 블록의 스테이트를 자주 읽는다.


특히 PoW 기반 퍼블릭 블록체인은 가장 최신 블록을 믿을 수 없기 때문에
일부러 약 1시간 전에 만들어진 블록의 정보를 읽는다.

각 블록에서 읽을 수 있는 스테이트를 매번 통째로 디스크에 저장한다면,
감당할 수 없을 정도로 디스크를 많이 사용할 것이다.
immutable한 트리 구조의 자료구조를 사용하면 쉽게 문제를 해결할 수 있다.
immutable한 트리를 수정하면 이전 트리는 그대로에, 변경뙨 사항들과 그들의 부모만 수정된
새로운 트리를 쉽게 만들 수 있다.


현재 데이터 이전 데이터
해시 기반
디프를 보기.
단점?
이게 끝인가?


## DB에 저장하는 Ethereum State Trie

이더리움의 스테이트 트라이를 처음 공부할 때, 잘 이해가 안가던 부분이 있었습니다.
바로 트라이 노드간의 레퍼런스를 어떻게 표현하는지, 그리고 그 연결 부분이 디비에 어떻게 저장되는지였습니다.

트라이는 트리의 한 종류입니다. 이 글에서는 이더리움 스테이트 트라이의 트리적인 특징에 대해
이야기 하겠습니다.

제가 그 때까지 알던 트리를 메모리에서 표현하는 방법은  두가지가 있었습니다. 각 노드를 힙에 할당한 뒤 자식 노드에 대한
포인터를 부모 노드에 저장합니다. 다른 방법은 perfect binary tree에서 각 노드를 어레이에 순서대로
저장하는 방법입니다. 이 방법을 쓰면 index의 연산으로 쉽게 자식 노드를 찾을 수 있습니다.
트리를 디스크에 저장할 때는 메모리의 표현 방식에 상관 없는 방법을 썼습니다. 정렬된 트리였다면 정렬된 원소들을
리스트 형태로 디스크에 저장했습니다. 아니면 트리 구조를 나타낼 수 있는 포맷인 JSON 이나 XML 같은 방법을 쓸 수 있구요.
SQL DB에 저장하는 데이터는 SQL에 저장할 때 생성한 ID를 레퍼런스로 썼습니다.

이더리움 스테이트 트라이는 놀랍게도 자식 노드의 Hash를 레퍼런스로 사용합니다.
메모리에 있을 때도 트라이의 모든 노드를 키밸류 자료구로(해시나 트리)에 저장합니다.
부모 노드는 자식노드의 해시값을 가지고 있어서 자식 노드의 해시를 키로 자식을 찾아옵니다.

트리를 구현하기 위해 또 다른 트리(혹은 해시테이블)을 쓰다니 저에게는 혁명적인 발상이었습니다.
한 번 더 재밌는 건 메모리에서의 표현 방법과 디스크에서의 표현 방법이 동일하다는 점입니다.
디스크에 저장할 때도 Level DB나 Rocks DB같은 key value 스토리지에 각 노드를 저장합니다.
사실상 메모리든 디스크든 구분할 필요가 없습니다.

또 알고보면, 지금 이더리움의 state trie는 일반 컴퓨터의 메모리에 담기엔 너무 큽니다.
자주 접근하는 노드는 메모리의 key value 스토리지에 캐시처럼 저장하고, 자주 안쓰는 데이터는
디스크에서 그때 그때 읽어오는 방법을 씁니다.

저는 항상 트리에서 노드들끼리 연결하는 방식은 디스크에 있을 때와 메모리에 있을 때 서로
다르게 표현될 것이라는 고정관념이 있었습니다. 이 틀에 맞지 않는 구조라 계속 헷갈렸던 거 같네요.

말 안하고 넘어가면 아쉬우니 하나 추가하자면, 이렇게 자식 노드의 해시를 노드의 포인터로 취급하여 같이 저장하기 때문에,
최상위 부모 노드의 해시는 트리 전체의 해시를 한 것과 같습니다. 아마 이 특징을 얻기 위해서
해시 값을 포인터로 쓴 것이라고 생각합니다. 블록체인에서 전체 상태의 해시값을 구하는 건 중요하니까요.

## Log structured sorted merge tree


### Log structured merge tree blog

내가 코드를 읽었던 블록체인 구현체들은 대체로 Log-structured merge-tree(LSM Tree) 기반의 key value 디비를 사용했다.
비트코인 코어는 LevelDB를 사용한다. 이더리움의 Go언어 구현체도 LevelDB를 사용한다.
Parity 이더리움(지금은 OpenEthereum)은 RocksDB를 사용한다. Cosmos도 LevelDB를 사용한다.

처음에는 RocksDB와 LevelDB가 SQL을 지원하지 않는 Key-Value형 DB라서 NoSQL들이 쓰는 자료구조인줄 알았다.
좀 더 찾아봤더니 SQL이든, NoSQL이든 상관없이 쓸 수 있는 자료구조였다.
내가 이전 프로젝트에서 썼던 elastic search도 LSM Tree를 쓰고 있었다.
MySQL에도 InnoDB대신 MyRocks는 스토리지 엔진을 사용하면 LSM Tree를 사용할 수 있다.
LSM Tree는 흔히 SQL 디비에서 사용하는 B-Tree에 대응되는 자료구조로 이해하면 된다.

블록체인이 RocksDB나 LevelDB같은 임베디드 디비를 쓰는 이유는 여러 가지가 있을 것이다.
더 편하게 배포를 할 수 있다. 블록체인 컨텍스트에 맞게 튜닝하기도 좋다.
내가 생각하는 가장 중요한 이유는 디비 구현체의 버전을 고정시키는 것이다.
2013년에 비트코인 코어 구현체는 0.8 버전으로 올리면서 Berkeley DB에서 LevelDB로
디비를 바꾸었다. 원치 않던 사이드 이펙트로 Berkeley DB에 있던 문제가 해결되었다.
이 때문에 네트워크가 0.8이전 버전과 0.8버전으로 나뉘는 심각한 문제가 있었다.[^1][^2]

[^1]:
  BIP 50 문서에 해상 이슈에 대한 포스트 모템 글이 정리되어 있다. [link](https://github.com/bitcoin/bips/blob/master/bip-0050.mediawiki)

[^2]: 비트코인과 이더리움 역사를 보면 재밌는 것들이 많다.

비트코인 코어는 LevelDB의 소스코드를 src/leveldb 서브디렉토리에 복사하여 본인들이 직접
코드 업데이트를 관리하고 있다. 이 [스택 오버플로우 답변](https://bitcoin.stackexchange.com/a/75147)을 보면
Window 지원과 체인 포크 방지를 위해 LevelDB를 포크했다고 설명하고 있다.
답변을 단 사람은 Pieter Wuille로 비트코인 코어 개발자다.

임베디드 디비로는 SQLite 역시 유명하다. SQLite 대신 LevelDB를 쓴 이유는 속도때문이라고 한다.
이 [스택 오버플로우 답변](https://bitcoin.stackexchange.com/a/48968)에서도 Pieter Wuille씨가
답변을 해주셨다. LSM Tree를 쓴다는 것 자체가 B-Tree에 비해 성능의 큰 이점은 아니라고 생각한다.
다만 SQLite는 SQL엔진을 올려서 값을 쓰기까지 복잡한 과정을 필요하지만, LevelDB는 key value 바이너리
데이터를 단순히 저장하기 때문에 그 차이가 나는 것 같다.

이 글을 쓰면서 Rocks DB 문서를 바탕으로 LSM Tree가 동작하는 방식을 [여기에](/) 정리했다.

LSM Tree의 동작은 재밌는 점이 많다. 디스크 쓰기는 랜덤보다 시퀀셜이 항상 더 빠르다고 많이 들어왔다.
하지만 시퀀셜 쓰기만으로 의미있게 데이터를 저장하는 건 불가능하다고 생각했다.
LSM Tree는 그걸 해냈다. 랜덤 쓰기를 하지 않는다. WAL는 append-only고, SST 파일은 한 번 쓰면 수정하지 않는다.
종종 여러 SST 파일을 합쳐서 새로운 SST 파일을 쓴다. 그래서 B Tree 구현체들에 비해서 쓰기속도가 더 빠르다고 한다.[^3]

[^3]: [간단한 벤치마크](https://github.com/wiredtiger/wiredtiger/wiki/Btree-vs-LSM)

그리고 LSM 역시 데이터를 immutable하게 다룬다. 최근에 [Ethereum에서 사용하는 immutable 자료구조](https://blog.majecty.com/posts/2020-12-28-b-ethereum-immutable-data-structure.html)에서도
이야기 했지만 immutable한 방식을 만나면 반갑다. 그래 더 빠른 성능을 위해서 immutable을 선택할 수도 있다고.






블록체인들이 쓴다.
성능 때문이란다.
embedded

서버 클라 구조를 쓰는 건 부담이 있을 수 있지
비트코인은 디비때문에 포크났대
역시 비트코인과 이더리움의 역사는 재밌어. 상상도 못해본 많은 일들이 일어나지

위키 링크 소개

이뮤터블해.
write 쉽게 하기 위해서 값을 수정을 하지 않는구나.
그래서 더 concurrent한 걸 쉽게 하는 거 같기도 하고.

bloom filter나 skip list, 다양한 자료구조가 혼합된 구조네.
비트코인이나 이더리움의 db파일을 보면 64MB정도 되는 sst파일들이 잔뜩 있는 걸 볼 수 있습니다.


### Log structured merge tree wiki

B-Tree나 LSM Tree나 사용하는 곳마다 세부사항이 다를 것이다. 나는 PostgreSQL에서 사용하는
B-Tree와 RocksDB에서 사용하는 LSM Tree를 기준으로 이야기 하겠다.

LSM Tree는 B-Tree에 비해 쓰기 속도가 빠르다. 대신 읽기는 더 느리다.

B-Tree에 비해서 LSM Tree는 꽤 복잡하다. 크게 봐서 3가지 방식으로 데이터를 관리한다.
하나는 메모리에 있는 MemTable, 다른 하나는 메모리에 있는 데이터를 로그 형식으로 일렬로 적는
WAL(Write ahead log), persistant하게 데이터를 보관하는 SST(Sorted String Table)이 있다.

LSM-Tree는 데이터를 빠르게 쓰는데 진심이다. 어떤 세부사항을 보더라도 쓰기 속도를 빠르게 하겠다는
결정이 눈에 보인다.

첫 번째 노력은 MemTable과 WAL파일이다. 디스크에 가장 빠르게 데이터를 쓰는 방법은 뭘까.
sequential하게 쓰는 것이다. 모든 쓰기 동작은 하나의 파일에 sequential하게 데이터들 적는다.
당연히 sequential한 데이터는 읽기가 힘들기 때문에 WAL파일에 있는 데이터를 메모리에서 쉽게
접근할 수 있게 MemTable을 사용한다.

MemTable은 최근에 쓴 데이터들을 빠르게 읽는 캐시 역할을 한다. RocksDB는 MemTable에 Skip list를 사용한다.
[^1] Skip list는 O(log n)에 값을 읽을 수 있고, O(log n)에 값을 쓸 수 있다. 또한 동시에 값을 쓸 수 있다.

두 번째 노력은 SST의 관리 방식에 있다. LSM Tree는 SST파일을 관리할 때 항상 sequential한 쓰기만 한다.
random한 쓰기를 하지 않는다. sequential한 쓰기가 random 쓰기보다 빠르기 때문이다.[^2]
MemTable과 WAL 파일에 쓴 데이터는 크기가 커지면 SST 파일을 만들어 디스크에 저장한다.

[^1]: RocksDB는 MemTable에서 사용하는 자료구조로 Skip list대신 다른 걸 선택할 수 있다. Skip list가 기본값이다.
[^2]: SSD는 하드 디스크에 비해서 random 쓰기가 빠르지만, SSD 역시 sequential 쓰기가 random 쓰기보다 빠르다. 페이지 단위로 쓰기와, 이전 페이지 가비지 처리 때문이다.

LSM Tree에서 M은 Merge를 의미한다. Merge가 없을 때를 먼저 생각해보자.
SST 파일은 key 기준으로 정렬되어 있다. SST 파일은 파일 안에 적힌 데이터의 시작 key와 끝 key의 정보가 있다.
여러 SST 파일들 사이에 키 범위는 겹칠 수 있다. 따라서 적절한 merge를 하지 않는다면,
하나의 키를 찾기 위해 모든 SST 파일을 열어봐야할 것이다.

LSM Tree는 적절한 Merge 과정을(Compaction 이라고도 부른다) 통해서 SST 파일을 합친다.
SST 파일을 합치는 과정은 merge sort에서 merge하는 것과 비슷하다.
언제 어떤 SST 파일들을 골라서 merge할 것인가가 중요하다.
이 Compaction를 잘 해야 O(log n)에 데이터를 조회할 수 있다.
Rocks DB는 두 가지 Compaction 방법을 쓴다. 그 중 Leveld Compaction[^3]의 동작원리를 보자.

[^3]: https://github.com/facebook/rocksdb/wiki/Leveled-Compaction

Leveld Compaction은 SST 파일들을 여러 레벨로 구분한다. 한 레벨의 SST 파일들은 전체 key 범위를 커버한다.
한 레벨의 SST 파일들은 서로 키가 겹치지 않는다. 높은 레벨은 낮은 레벨보다 n배 더 많은 크기의 값을 가진다.
데이터의 갯수가 _m_이라고 할 때 레벨의 갯수는 _log m_ 이다.
한 레벨의 SST 파일들끼리 키가 겹치지 않는 특징 때문에 데이터를 찾기 위해서 level 갯수 만큼만 쿼리하면 된다. 따라서 O(log n)의 시간 안에 데이터를 찾을 수 있다.

Leveld Compaction은 다음과 같이 일어난다. 먼저 MemTable이 꽉 찼을 때 Level0에 SST파일들이 쌓인다. Level0만이 다른 Level들과는 다르게
같은 레벨이어도 키가 겹칠 수 있다. Level0에 쌓인 SST파일들이 설정해두었던 한계를 넘으면 Level0의 SST 파일들과 범위가 겹치는
Level1의 SST파일들을 합쳐서 새로운 SST 파일들을 만든다. 이 SST 파일들은 Level1에 속한다.
이 과정으로 인해서 Level1에 있는 SST 파일들이 한계를 넘었다면, Level1의 일부 SST 파일들을 범위가 겹치는 Level2의 파일들과 합친다.
이를 가장 마지막 Level까지 반복한다.[^4]

[^4]: [RocksDB wiki](https://github.com/facebook/rocksdb/wiki/Leveled-Compaction) 이해를 돕는 그림들이 있다.

컴팩션과정에서 보는 것과 같이 SST파일들은 수정되지 않는다. 다음 레벨로 이동하면서 새로운 SST 파일을 만든다.

데이터를 찾는 과정을 정리하자면 다음과 같다.
먼저 MemTable에서 찾는다. 없으면 낮은 level부터 찾는다. 가장 높은 level에서도 발견하지 못했다면 해당 키가 저장되어 있지 않다.

LSM Tree의 약점은 조회다. 없는 키를 조회할 때가 최악의 시나리오다.
메모리에서 한 번, 레벨 0에서 여러번, 그 이후 레벨 별 한 번씩 조회를 해서 전부 값을 찾을 수 없어야 해당 키가 없다고 알 수 있다.
한 레벨 안에서 조회를 할 때도 다음 과정을 거친다. SST 파일 별 키 레인지를 통해 들어있을 가능성이 있는 SST 파일을 찾는다.
해당 SST 파일 안에서 다시 binary search과정을 통해 실제 키가 없는지 확인한다.

RocksDB는 이 "없는 키 조회과정"을 빠르게 만들기 위해서 Bloom Filter를 사용한다.[^5] Bloom Filter는
일종의 해시테이블로, 확률적으로 해당 키가 없음을 알려준다. Bloom Filter가 키가 있다고 하면
정말로 키가 있을 수도 없을 수도 있다. Bloom Filter가 키가 없다고 하면 정말로 없다.

[^5]: https://github.com/facebook/rocksdb/wiki/RocksDB-Bloom-Filter

## bloom filter

블룸필터는 어떤 원소가 집합에 있는지 확인하기 위해 사용할 수 있는 확률적인 자료구조다.
시간이 오래걸리는 조회를 빠르게 하기 위해서 사용한다.

블룸필터를 공부했을 때 캐시와 비슷하다고 느꼈다.
프로그래밍에서 캐시는 어디에서는 쉽게 볼 수 있는 구조다.
캐시는 프로그램에 성능문제가 있을 때 쉽게 고려할 수 있는 해결책이다.
전체 구조를 바꾸지 않고도 쉽게 적용할 수 있다.
게임 서버 개발을 할 때에도 여러번 DB를 조회해야 얻을 수 있는 자료를
멤캐시나 레디스에 저장하여 빠르게 조회할 수 있게 했었다.

블룸필터는 캐시처럼 만능은 아니지만 꽤 비슷하게 쓸 수 있다.
블룸필터는 어떤 집합에 원소가 있는지 찾을 수 있는 자료구조다.
블룸필터가, 원소가 집합에 없다고 하면 정말로 집합에 해당 원소가 없다.
블룸필터가, 원소가 집합에 있다고 하면 집합에 자료가 있을 수도, 없을 수도 있다.

최근에 작성했던 RSM Tree 글에서도 블룸 필터가 나왔었다.
RSM Tree는 없는 값을 조회할 때가 가장 성능이 느리다. MemTable, 여러 SST 파일 들에서
값을 전부 검색해보고, 모든 곳에서 값이 없음을 확인해야 한다.
특히 SST 파일은 수십 MB 크기일 수도 있기 때문에 SST 파일을 바이너리 서치할 때
여러 번의 디스크 읽기 요청이 발생한다.
SST 파일마다 Bloom Filter를 넣어둠으로써, 디비 읽기 요청 횟수를 많이 줄일 수 있다.

블룸 필터의 원리는 발상의 전환이라고 생각한다.
해시테이블에서 다른 키가 같은 테이블의 장소를 가리키면 피곤하다.
링크드 리스트를 쓰던, 다른 해시함수를 돌려서 다른 위치를 찾던 다른 자리를 찾아서 마련해 주어야 한다.

블룸필터는

프로그램의 성능에 문제가 있을 때 쉽게 고려할 수 있다. 전체 구조ㄴ

## 내 트랜잭션이 멤풀에 들어있을까

멤풀에서 트랜잭션을 관리하는 법. 무엇이 중요할까?
내가 넣은 트랜잭션이 영원한 것?
미래의 트랜잭션도 잘 관리하는 것?
트랜잭션을 얼마나 가지고 있고 얼마나 전달해야 할까.

트랜잭션의 비용, 내가 넣었는지,
무슨 이야기를 해야 재밌을까.

## 블록과 트랜잭션의 전파

무엇을 신경써야 할까. 이미 보낸 것을 저장하고 있기.
중요한 것들을 보내기 ban시켜야 할까?
어떻게 해야 블록과 트랜잭션을 잘 전달할까.
검즌을 해서 전달을 해야 할까?

## 블록체인의 deterministic

블록체인의 특징 중 많은 부분이 개발을 힘들게 한다.
p2p는 모두가 동등해서, 서버 클라 구조보다 쉬울 줄 알았다.
웬걸, p2p는 서버와 클라가 동시에 있는 거였고, 내가 서버 역할을 해야 하나, 클라 역할을 해야 하나
구분해야 했다. 내가 A보다는 정보를 많이 가지고 있어서 A에게는 정보를 주는 역할을,
나보다 B가 정보를 많이 알고 있기 때문에 B에게는 정보를 요청하는 역할을 해야 한다.
두 기능이 하나의 코드베이스에 있으니 많이 헷갈린다.

PoW에서 블록이 언제든지 바뀔 수 있다는 점도 문제였다.

하지만 하나 좋은 점이 있다면, 모든 것이 deterministic하다는 점이다.
원본 데이터의 정의가 확실하다. 블록, 블록에 들어있는 정보가 모든 정보의 원천이다.
나머지 정보는 언제든지 해당 블록에서부터 계산할 수 있다.

트랜잭션은 언제 어디서나 원하는 state에서실행할 수 있다.

## 크립토 관련 할 이야기는

private 키를 조심히 관리하기
파일에 저장할 때 password는?
언제 어디까지 안전한가.
PoW에서는 키가 필요 없었는데.

## 키를 잘 관리하자

블록체인에서 비밀키는 유일하고 대체 불가능한 신분증입니다.
잃어버리면 다시는 재발급받을 수 없고, 묶여있던 재화를 모두 잃어버립니다.
비밀키는 어떻게 해야 잘 괸리할까요?

첫 번째는 백업입니다. 인터넷과 연결되지 않은 매체에 저장하길 추천합니다.
USB 기반의 하드웨어 월렛도 좋습니다.
QR코드로 변환해서 프린트해놓는 것도 좋고,
Mnemonic 키를 일기장에 적어놓는 것도 좋습니다.

이렇게 백업한 키를 사용할 때는 역시 인터넷이 연결안 된 컴퓨터에서 트랜잭션을
서명하기 위해서만 잠시 사용하고 다시 지우는 게 좋습니다.

귀찮아서, 혹은 내가 비트코인이나 이더리움을 얼마 가지지 않고 있다면
자주 쓰는 컴퓨터에 저장해도 괜찮습니다.
단 이 때는 비밀키를 암호화해야 합니다.
이더리움 지갑들은 키를 생성할 때 비밀번호를 받아서 키를 암호화해서 저장합니다.
지갑에서 비밀키를 내보낼 때도 일반적으로 비밀번호를 받아서 암호화해서 저장합니다.
비밀번호는 암호화된 비밀키와 다른 매체에 저장해야 안전합니다.

---

어플리케이션에서 사용하는 비밀키는 어떻게 관리할까요.
비트코인, 이더리움과 연동되어 트랜잭션을 생성하는 프로그램은
평문으로된 비밀키 값을 얻을 수 있어야 합니다.
일반적으로 파일 시스템에 비밀키를 저장합니다.
적어도 키 값을 저장한 파일의 소유권을 잘 지정하고, 서버 자체가 해킹당하지 않도록
방화벽과 계정을 잘 관리해야 합니다.

트랜잭션 서명만 하는 별도의 서버를 만들면 더 안전합니다.
해당 서버는 서명을 요청하는 서비스만 접근할 수 있게 방화벽을 잘 설정해두어야 합니다.
서명할 때에도 트랜잭션의 내용을 확인하고 특정 규칙에 맞는 트랜잭션만 서명하도록 하면 더 좋습니다.
하루에 출금할 수 있는 금액의 제한을 건다거나 특정 계좌로만 보낼 수 있게 만들 수 있습니다.

---

키를 여러개 나누는 것도 보안의 이점이 있습니다. 비트코인이나 이더리움이나 멀티시그니쳐지갑을
쓸 수 있습니다. 멀티시그니쳐지갑은 n개의 키 중 m개의 키로 만든 서명이 있을 때만 비트코인이나 이더리움을 송금하게 만들 수 있습니다.
여러 사람이 멀티시그니쳐지갑의 키를 하나씩 가지는 게 기본 사용법입니다.
키를 한 사람이 가지되 각각의 키의 백업 방식을 다르게 저장하는 것도 응용법입니다. 3개의 키중 2개의 서명으로
비트코인을 보낼 수 있는 멀티시그니쳐지갑이 있으면, 키 하나를 구글 드라이브에, 하나를 1password에, 남은 하나를
하드웨어지갑에 저장할 수 있습이다. 이렇게하면 1개를 해킹당해도 안전합니다.

Shamir Secret Sharing을 통해서 n개의 키 분할 중 m개의 키를 모으면 원본 키가 만들어지게 할 수 있습니다.
Shamir Secret Sharing과 멀티시그니쳐지갑은 큰 차이점이 있습니다. Shamir Secret Sharing은
하나의 키를 여러개로 나눈 뒤 나중에 다시 헙쳐서 원본 키를 만드는 방식입니다. 멀티시그니쳐지갑은
애초에 서로 다른 키가 여러개 있습니다. 각각의 키로 서명을 한 뒤 서명의 갯수를 확인하는 방법입니다.

다만 Shamir Secret Sharing은 쓸 때 신중해야 합니다.
Shamir Secret Sharing은 한 번 키를 모으면 원본키가 복원됩니다.
1회용이라 생각하고 사용해야 합니다.
Shamir Secret Sharing에서 여러 키를 만들 때 가장 간단한 방법은 원본 키를 먼저 만들고 이를 나누는 것입니다.
DKG와 같은 복잡한 단계를 거치면 아무도 원본키를 모르는 상태로 키를 나눌 수 있습니다.

---

비밀키를 사용하는 어플리케이션을 만들 때에도 보안에 신경쓸 점들이 있습니다.
가능한한 메모리에 비밀키가 있는 시간을 줄이는 것이 좋습니다.
많은 crypto 라이브러리들이 메모리를 청소하는 함수들을 제공해줍니다. 잊지 말고 잘 호출해 주어야 합니다.

비밀키는 평범한 String이나 buffer를 쓰기보다, 특별한 타입을 선언해서 써야 합니다.
실수로 serialize되거나 ToString 같은 함수로 내부 정보가 출력되지 않게 만들어야 합니다.
직접 serialize를 하지 않더라도, 프로그램이 예상치 못하게 종료될 때 콜스택에 있는 값들을
출력해줄 때가 있습니다. 자신이 사용하는 언어가 언제 값을 출력하고, 어떻게 해야 그것을 막을 수 있는지 알아야 합니다.

---

당연하지만, 서명을 하려면 메모리에 암호화가 되지 않은 비밀키 정보가 있어야 합니다.
Intel SGX와 같은 TEE(Trusted Execution Environment)를 사용하면, 서명 알고리즘이 동작하고 있는 와중에도
메모리에 있는 비밀키가 암호화되어 있도록 만들 수 있습니다.







여기까지가 제가 알고있는, 비밀키를 안전하게 다루는 방법입니다.
하지만 기술과 별개로 어려운 일들이 많습니다.

예를들어 개발자가 시스템의 모든 리소스에 접근할 수 있다면 안전할까요?
해당 개발자가 퇴사를 했다면? 개발자의 작업 컴퓨터에 저장되어있던 서버 접근용 키가 도난당했다면?
SSH로그인 방식으로 Certificate authentication 를 사용한다면, 키가 도난당하는 문제는방지할 수 있습니다.

키를 안전하게 지키는 방법은 끝이 없다고 생각합니다.
현금도, 


여기까지는 키를 관리하는 기술의 문제였습니다.
다양한 방법을 써서 키를 관리하더라도, 작업하는 개발자가 

그러면 키를 아무도 모르게 관리할 수 있을까요?
자동으로 키를 생성. 어딘가에 접근할 수 없게 백업. ZCash 키 생성 후 파괴.

비밀키를 잃어버린 7가지 사례: https://www.qredo.com/blog/proofofkeys-7-ways-private-keys-have-been-compromised-and-how-you-can-protect-yourself

하지만 키를 어떻게 관리하든 걱정이 된다.
시스텡을 개발하는, 그리고 디버깅하는 사람 누군가가 키를 읽고, 백업하는 과정을 해야한다.
누군가가 껴서 해야 한다는 의미다.



Private key는 중요하다. 소중하다.
잘 관리해야 한다.

한 곳만 뚫려도 안전해야 한다.
기본적으로 비밀번호를 사용해서 디스크에 저장한다.
디스크가 털려도 쉽게 털리지 않는 방법이다.

PoW 노드는 서명할 일이 없었다.
PoS는 서명해야 한다. 계정을 디스크에 저장할 수 밖에 없다.
계정 관리를 잘 하자.
노드를 인터넷에 공유하기 보다 다른 노드를 통해서 통신하게 하는 게 좋을 것.

## 블록 싱크

때로는 전혀 상관없다고 생각한 모듈들 끼리 연관되어있기도 한다.
코드체인은 컨센서스를 교체할 수 있는 블록체인 엔진이다.
기반은 PoW로 작성하고 뒤에 PoS 컨센서스 엔진을 추가했다.
컨센서스는 블록을 확정하는 방법에 대한 것이기 때문에 블록체인의
다른 부분들, 예컨대 블록과 트랜잭션의 전파, 트랜잭션의 실행,
블록 정보의 저장 등의 코드와는 연관이 없을 거라고 생각했다.

아니었다. PoS 컨센서스 알고리즘은 PoW와 가정하는 상황이 다르다.
이 서로 다른 가정은 인터페이스로 추상화할 수 없는 영역이었다.
이 가정의 차이는 영향 없어보이는 여러 곳에 불쑥 나타나 문제를 일으켰다.
그 중 하나가 블록의 전파였다.

블록체인은 컨센서스는 모두가 인정할 블록의 규칙을 정하는 것이다.
PoW에서는 블록의 해시값이 특별한 규칙에 맞으면 해당 블록이 인정된다.
PoS, 내가 작업했던 텐더민트 알고리즘은 정해진 위원회의 서명이 들어있는 블록이
인정되었다.

블록 전파는 컨센서스와 상관 없어 보인다. 블록을 생성하는 노드가
규칙에 맞게 블록을 생성하면, 해당 노드는 새로 생성한 블록을 피어들에게 뿌린다.
새로운 블록을 받은 피어는 해당 블록을 검증한 뒤에 문제가 없으면 다시
자신의 피어들에게 뿌린다.

문제는 디테일에 있었다. 비트코인과 이더리움은 블록을 받고 검증하는 과정의 효율을 위해서
블록을 헤더와 바디(트랜잭션의 목록)으로 나눈 뒤 헤더를 먼저 받는다.
헤더는 블록 전체에 비해서 크기가 상당히 작지만, 잘못된 헤더를 만드는 것을 무척 어렵다.
PoW 컨센서스에서 거짓 헤더를 만드는 일은 새로운 블록을 만드는 것 만큼 어렵다.
거짓 헤더를 만들 바에 새로운 블록을 만드는 데 참여하여 비트코인이나 이더리움을 보상으로 받는 것이
이득이다. 따라서 헤더 먼저 받는 전략은 유효하다.

PoS는 그렇지 않았다. PoW처럼 헤더의 해시값을 계산하는 것 만으로 유효한 검증을 할 수 없다.
PoS에서는 벨리데이터 셋을 알아야 블록을 검증할 수 있다.
또한 과거의 위원회는 믿을 수 없게 되기 때문에[^1] 처음부터 블록을 받아오려면
블록체인 네트워크 외부에서 믿을 수 있는 헤더의 정보를 받아와야 한다.

[^1]: 이를 이용한 공격을 Long Range Attack이라고 부른다.

이 현상이 신기했다. 무엇이 이 관련없는 두 컴포넌트를 강하게 결합시켰을까.
이를 미리 파악할 수 있었을까? 코드에서 이를 잘 표현할 수 있었을까?
나는 일정 계산에 약하다. 일정 계산에서 중요한 건 미리 이슈들을 파악하는 것이다.
A를 변경했을 때 미칠 영향을 어디까지인지 미리 파악해야 대략적인 변경의 규모를
예측할 수 있다.

컨센서스 알고리즘의 추가는 그런 면에서 영향력이 매우 큰 변경서항이었다.
같은 PoW 알고리즘에서 다른 걸 쓰는 건 변경사항의 영향력이 작다.


### 블록 싱크 시도 1월 11일 18시 29분

블록은 언제 왜 싱크할까?
블록 싱크에 대해서 의미있는 이야길 할 수 있을까?
내가 생각하기에 블록 싱크는 무엇이었을까?
블록 싱크는 레이지하게 다음 정보를 받음.
쓰르풋을 어떻게 관리할까.
큐가 쌓여있으면 어떻게 처리할까.
차라리 블록체인 PoW에 비해서 PoS로 갈 때 귀찮았던 걸 이야기할까? 이게 좋겠다.

비트코인과 이더리움은 블록을 서로 교환할 때 헤더를 먼저 교환하고
그 뒤 블록 전체 정보를 교환한다.
이더리움은 헤더를 바는 걸 헤더싱크, 남은 블록을 받는 걸 바디싱크라고 부른다.
비트코인은 헤더를 먼저 받는 전략을 Header-First 전략이라고 부른다.

코드체인은 PoW와 PoS를 동시에 지원했다.
블록체인에서 합의 알고리즘을 모듈화 하여 쉽게 갈아끼울 수 있게 만들었다.
하지만 컨센서스 알고리즘의 다른 특징들은 블록체인의 다른 모듈에도 큰 영향을 미쳤다.
그 중 하나가 블록싱크였다.

블록은 블록 헤더와 트랜잭션들로 이루어져 있다. 헤더엔 여러가지 메타정보가 들어있다.
많은 경우 블록 헤더만 받아도 유용한 검증을 할 수 있기 때문에, 헤더를 먼저 받고
검증을 한 후 트랜잭션 리스트를 나중에 받는게 일반적이다.

비트코인이나 예전 이더리움처럼 PoW 체인은 헤더의 해시만으로도 꽤나 의미있는 검증을 할 수 있다.
PoW는 규칙을 따르는 헤더를 만들기 위해서 엄청난 양의 돈을 들여야한다.
거짓 헤더를 만드는 비용이 너무 비싸기 때문에 헤더 해시만으로도 이상한 데이터인지 쉽게 검출할 수 있다.

PoS는 PoW에서 하는 그 엄청난 전력낭비를 줄이고자 하는 컨센서스 알고리즘이다.
특별한 조건의 해시 대신, 위원회 위원들의 서명을 통해 블록을 증명한다.
이 검증은 PoW에서만큼 간단하지 않다. 위원회의 위원 목록이 언제든지 바뀔 수 있으므로,
위원의 목록을 스테이트에서 읽어와야 한다. 블록체인 스테이트를 읽으려면 이전 블록까지의
모든 블록 데이터가 필요하다. 따라서 가볍게 헤더만 먼저 싱크받아 검증받는 게 불가능해진다.

이를 해결하기 위한 몇가지 방법이 있다. 다음 위원회 셋 정보를 헤더에 담는 방법이 그 중 하나이다.
이렇게 하면 해당 블록에 서명한 현재 위원회가 다음 위원회를 인증하는 방식이 된다.
내가 한 시점에 믿을 수 있는 벨리데이터 셋을 알고 있다면, 그 뒤로는 믿음을 확장시켜
헤더만으로도 검증이 가능해진다.

롱레이지 어택은 PoS 체인에서 과거의 위원회가 자신의 키를 돈 주고 팔았을 상황을 가정한다.
이 상황에서 오래된 블록에 대한 서명은 믿을 수 없게 된다. 이를 해결하기 위해서는
믿을 수 있는 헤더들의 정보를 블록체인 네트워크 밖에서 얻어야 한다.




### 문제의 근본적인 원인.

현재 시점의 재화를 담보로 건다는 것.

PoW 혹은 PoS 규칙에 따라 생성된 블록은 네트워크의 모든 피어에게 퍼져나간다.
피어로부터 블록을 받은 노드는 블록을 검증하는 과정을 거친다.

피어로부터 블록을 받을 때 피어를 믿을 수 없기 때문에 블록을 검증해야 한다.
블록의 데이터를 전부 받으면 필요한 모든 검증을 할 수 있다.


단점은 블록의 크기가 수 메가바이트까지 할 수 있으므로 쉽게 DoS공격을 할 수 이
가장 간단한 방법은 블록의 데이터를 모두 받는 것이다.
블록의 정보를 모두 받는 게 가장 간단하다. 필요한 정보가 모두 있으므로
데이터의 검증을 모두 하면 된다.

이 때의 문제는 블록 하나의 크기가 몇 메가바이트나 된다는 점이다.


하지만 블록의 데이터는
너무 크다. 블록의 메타정보를 가지고 있는 헤더와 트랜잭션들로 이루어진 바디로 구성된다.
PoW 컨센서스는 블록 헤더의 nonce값을 수정하며 특정한 패턴의 해시값을 만든다.
블록 헤더의 해시값만 검증하기만 해도 엉터리 블록들을 손쉽게 걸러낼 수 있다.

만약 유효하지 않은 블록의 헤더들로 원본 체인과 비슷한 수준의 해시들을 만들어 내려면
엄청난 돈이 필요하다. 가짜 블록을 생성해서 퍼뜨리는 것 만으로는 그만한 이득을 얻을 수 없다.
따라서 헤더 검증만으로 많은 문제점들을 해결할 수 있다.

PoS에서는 이 이야기가 통하지 않는다.
블록의 헤더에는 벨리데이터들의 서명이 들어가 있다.
벨리데이터들이 진짜 벨리데이터인지 알려면 블록체인 스테이트를 읽어서
지금 시점의 벨리데이터셋을 검증해야 한다.
결국 헤더 검증을 위해서 바디를 전부 받아 스테이트를 만들어내야 한다.

물론 방법은 있다.

방법 하나는 이전 벨리데이터 셋이 다음 벨리데이터 셋을 검증하는 방식을 사용하는 것이다.
헤더에 현재 벨리데이터셋의 정보와 다음 벨리데이터셋의 정보를 넣는 것이다.
이전의 벨리데이터 셋을 믿는 것이므로 제네시스부터 시작해서 믿음을 이어나갈 수 있다.

하지만 여기서도 문제가 되는 게 있다.
벨리데이터는 보통 체인에 많은 돈을 맡겨 두어야 한다.
잘몽된 행동을 하면 맡겨둔 돈을 잃어버리기 때문에 우리는 벨리데이터를 신뢰한다.
그렇다면 과거의 벨리데이터는? 벨리데이터로 일 하다가 은퇴하고
맡겨둔 돈 다 뺀 사람은 정직해야 할까?
PoS에서 이렇게 옛날에 벨리데이터였던 키를 사용하여 공격하는 걸 long range attack이라고 부른다.

PoS는 


Genesis부터 이어가던 방식은 Genesis를 결국 믿지 못하기 때문에 쓸 수 없다.
그렇다면 반대는 어떨까. 블록체인 외부에서 믿을 수 있는 현재 밸레데이터 셋을 받아와서
역순으로 블록을 받는 것이다.

이를 우회하기 위한 전략이 몇 가지 있다.

하나는 이전 벨리데이터 셋이 다음 벨리데이터 셋을 검증하는 방식을 사용하는 것이다.
쭉 따라올라갈 수 있다.
( 이 글에서는 과거의 키가 도난당하거나 팔렸다는 가정을 하지 않겠다. weak subjectivity는
다른 주제다.)

Long Range Attack은 가장 최신 블록을 알고 있는 노드에게도 성립하는 공격이다.
이 공격을 막기 위해 weak subjectivity라는 획기적인 방법을 사용하는데, 이는
여기서 이야기하진 않겠다.



### assume valid in bitcoin

Bitcoin checkpoint from 0.3.2
Bitcoin Minimum Chainwork?
	오호라 최소한의 chainwork보다 큰 거만 받겠다 이거지
checkpoint는 무조건 해당 체크포인트가 체인 내에 있어야 해.
assume은 있으면 안전. 없어도 괜찮.

Ethereum haredcoded check point
Ethereum checkpoint oracle
https://github.com/ethereum/go-ethereum/blob/053ed9cc847647a9b3ef707d0efe7104c4ab2a4c/cmd/checkpoint-admin/README.md


### 블록 싱크 이전 시도 1월 10일 10시 28분

퍼블릭 블록체인의 노드들은 두가지 중요한 일을 합니다.
하나는 트랜잭션과 블록을 다른 노드들에게 전파하는 것이고,
다른 하나는 받은 트랜잭션과 블록을 검증하는 일입니다.

P2P에서는 피어가 주는 모든 데이터를 검증해야 합니다.
피어로부터 온 블록도 항상 검증해야 합니다.

노드가 상대방으로부터 많은 데이터를 받을 때 

블록 싱크는 헤더 싱크와 바디싱크로 나뉩니다.

블록을 다운 받으면 검증을 합니다.

왜 헤더를 먼저 받을까요

블록은 용량이 너무 커서
믿지 못해서. 

## 실패한 트랜잭션을 버려도 되나요

## 중복 방지의 어려움

## 빠르고 안전하기 싱크하는 법

## DB 이야기

## PostgreSQL과 Compaction

## 여러 체인이 소통하기. 어떻게 상대방을 믿을까

## sequence와 UTXO 둘다 앱만들기는 어렵다

## forward secrecy

